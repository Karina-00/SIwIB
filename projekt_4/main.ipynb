{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-03T14:40:39.625095Z",
     "start_time": "2024-05-03T14:40:39.611764Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from dataclasses import dataclass, asdict\n",
    "from collections import defaultdict\n",
    "import xml.etree.ElementTree as ET\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn.utils.rnn import pack_sequence, pad_sequence\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4391d891c1860350",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-03T14:40:39.630509Z",
     "start_time": "2024-05-03T14:40:39.626103Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "DATA_DIR = \"./RNA-Puzzles\"\n",
    "RESULTS_FILENAME = \"filter-results.txt\"\n",
    "N = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e0a79defcc23c81b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-03T14:40:39.678062Z",
     "start_time": "2024-05-03T14:40:39.665518Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def float_or_none(val: str):\n",
    "    return None if val == \"-\" else float(val)\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class NativeMotive:\n",
    "    name: str\n",
    "    segments_count: int\n",
    "    residues_count: int\n",
    "    nucleotide_ranges: list[str]\n",
    "    sequences: list[str]\n",
    "\n",
    "    @staticmethod\n",
    "    def from_split_line(l: list[str]):\n",
    "        return NativeMotive(\n",
    "            name=l[0],\n",
    "            segments_count=int(l[1]),\n",
    "            residues_count=int(l[2]),\n",
    "            nucleotide_ranges=list(map(lambda x: x.strip(), l[3].split(\",\"))),\n",
    "            sequences=list(map(lambda x: x.strip(), l[4].split(\",\")))\n",
    "        )\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class NucleotideTorAngles:\n",
    "    chain: str\n",
    "    residue_num: int\n",
    "    name: str\n",
    "    alpha: float\n",
    "    beta: float\n",
    "    gamma: float\n",
    "    delta: float\n",
    "    epsilon: float\n",
    "    zeta: float\n",
    "    chi: float\n",
    "\n",
    "    @staticmethod\n",
    "    def from_split_line(l: list[str]):\n",
    "        return NucleotideTorAngles(\n",
    "            chain=l[0],\n",
    "            residue_num=int(l[1]),\n",
    "            name=l[3],\n",
    "            alpha=float_or_none(l[4]),\n",
    "            beta=float_or_none(l[5]),\n",
    "            gamma=float_or_none(l[6]),\n",
    "            delta=float_or_none(l[7]),\n",
    "            epsilon=float_or_none(l[8]),\n",
    "            zeta=float_or_none(l[9]),\n",
    "            chi=float_or_none(l[10])\n",
    "        )\n",
    "    \n",
    "@dataclass\n",
    "class MotivePrediction:\n",
    "    name: str\n",
    "    rmsd: float\n",
    "    nucleotide_tor_angles: list[NucleotideTorAngles]\n",
    "    \n",
    "\n",
    "def get_tor_angles_from_file(filename: str) -> list[NucleotideTorAngles]:\n",
    "    res = []\n",
    "    with open(filename) as target_tor_file:\n",
    "            next(target_tor_file)\n",
    "            for line in target_tor_file:\n",
    "                split_line = line.strip().split(\"\\t\")\n",
    "                try:\n",
    "                    res.append(asdict(NucleotideTorAngles.from_split_line(l=split_line)))\n",
    "                except ValueError:\n",
    "                    pass\n",
    "    return res\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b8a468b7cfff9e9a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-03T14:40:41.256187Z",
     "start_time": "2024-05-03T14:40:39.749069Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['pz01',\n",
       " 'pz02',\n",
       " 'pz03',\n",
       " 'pz04',\n",
       " 'pz05',\n",
       " 'pz06',\n",
       " 'pz07',\n",
       " 'pz08',\n",
       " 'pz09',\n",
       " 'pz10']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "puzzles = os.listdir(os.path.join(os.curdir, DATA_DIR))\n",
    "puzzles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b9c1939a7d372c1c",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-05-03T14:40:41.260195Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "native_motives = defaultdict(list[NativeMotive])\n",
    "\n",
    "for puzzle in puzzles[:N]:\n",
    "    with open(os.path.join(os.curdir, DATA_DIR, puzzle, RESULTS_FILENAME)) as results_file:\n",
    "        for line in results_file:\n",
    "            split_line = line.strip().split(\"\\t\")\n",
    "            # TODO filter by segments count > 2/3?\n",
    "            native_motives[puzzle].append(\n",
    "                NativeMotive.from_split_line(l=split_line)\n",
    "            )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "57514034a30d32a8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-03T14:40:41.262200Z",
     "start_time": "2024-05-03T14:40:41.261194Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "motive_solutions = defaultdict(lambda: defaultdict(dict))\n",
    "for puzzle in puzzles[:N]:\n",
    "    for native_motive in native_motives[puzzle]:\n",
    "        if not all(\n",
    "                [\n",
    "                    os.path.exists(os.path.join(os.curdir, DATA_DIR, puzzle, f'{native_motive.name}-rmsd.xml')),\n",
    "                    os.path.exists(os.path.join(os.curdir, DATA_DIR, puzzle, f'{native_motive.name}.tor'))\n",
    "                ]\n",
    "        ):\n",
    "            continue\n",
    "        \n",
    "        motive_solutions[puzzle][native_motive.name]['native_motive'] = native_motive\n",
    "        motive_solutions[puzzle][native_motive.name]['target_tor_angles'] = get_tor_angles_from_file(os.path.join(os.curdir, DATA_DIR, puzzle, f'{native_motive.name}.tor'))\n",
    "        motive_solutions[puzzle][native_motive.name]['predictions'] = []\n",
    "        pred_files = list(filter(lambda x: x.endswith(\".tor\"), os.listdir(os.path.join(os.curdir, DATA_DIR, puzzle, native_motive.name))))\n",
    "        for pred_file in pred_files:\n",
    "            motive_solutions[puzzle][native_motive.name]['predictions'].append(\n",
    "                MotivePrediction(\n",
    "                    name=pred_file[:-4],\n",
    "                    rmsd=-1,\n",
    "                    nucleotide_tor_angles=get_tor_angles_from_file(os.path.join(os.curdir, DATA_DIR, puzzle, native_motive.name, pred_file))\n",
    "                )\n",
    "            )\n",
    "        xml_tree = ET.parse(os.path.join(os.curdir, DATA_DIR, puzzle, f'{native_motive.name}-rmsd.xml'))\n",
    "        prediction_scores = {s.find('description/filename').text[:-4]: float(s.find('score').text) for s in xml_tree.getroot().findall('structure')}\n",
    "        \n",
    "        for pred in motive_solutions[puzzle][native_motive.name]['predictions']:\n",
    "            pred.rmsd = prediction_scores[pred.name]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10df3b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "motive_solutions['pz01']['1_solution_0_rpr_B_18_U']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93506b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "struktura słownika\n",
    "motive_solutions{\n",
    "    puzzle_name: {\n",
    "        motive_name: {\n",
    "            native_motive: NativeMotive() - klasa,\n",
    "            target_tor_angles: list[dict(NucleotideTorAngles())] - lista kątów kolejnych nukleotydów z natywnego motywu,\n",
    "            predictions: [\n",
    "                MotivePrediction(\n",
    "                name=...,\n",
    "                rmsd=...,\n",
    "                nucleotide_tor_angles: list[dict(NucleotideTorAngles())] - lista kątów kolejnych nukleotydów z danej predykcji motywu\n",
    "                ),\n",
    "                ...\n",
    "            ] - lista wszystkich predykcji dla danego motywu\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "db6ccdf9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>puzzle</th>\n",
       "      <th>native_motive</th>\n",
       "      <th>set</th>\n",
       "      <th>target_tor_angles</th>\n",
       "      <th>prediction_motive_name</th>\n",
       "      <th>rmsd</th>\n",
       "      <th>nucleotide_tor_angles</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pz01</td>\n",
       "      <td>NativeMotive(name='1_solution_0_rpr_A_3_G', se...</td>\n",
       "      <td>test</td>\n",
       "      <td>[{'chain': 'A', 'residue_num': 1, 'name': 'C',...</td>\n",
       "      <td>1_bujnicki_1_rpr</td>\n",
       "      <td>4.643</td>\n",
       "      <td>[{'chain': 'A', 'residue_num': 1, 'name': 'C',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pz01</td>\n",
       "      <td>NativeMotive(name='1_solution_0_rpr_A_3_G', se...</td>\n",
       "      <td>test</td>\n",
       "      <td>[{'chain': 'A', 'residue_num': 1, 'name': 'C',...</td>\n",
       "      <td>1_bujnicki_2_rpr</td>\n",
       "      <td>4.495</td>\n",
       "      <td>[{'chain': 'A', 'residue_num': 1, 'name': 'C',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pz01</td>\n",
       "      <td>NativeMotive(name='1_solution_0_rpr_A_3_G', se...</td>\n",
       "      <td>test</td>\n",
       "      <td>[{'chain': 'A', 'residue_num': 1, 'name': 'C',...</td>\n",
       "      <td>1_bujnicki_3_rpr</td>\n",
       "      <td>3.862</td>\n",
       "      <td>[{'chain': 'A', 'residue_num': 1, 'name': 'C',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pz01</td>\n",
       "      <td>NativeMotive(name='1_solution_0_rpr_A_3_G', se...</td>\n",
       "      <td>test</td>\n",
       "      <td>[{'chain': 'A', 'residue_num': 1, 'name': 'C',...</td>\n",
       "      <td>1_bujnicki_4_rpr</td>\n",
       "      <td>4.514</td>\n",
       "      <td>[{'chain': 'A', 'residue_num': 1, 'name': 'C',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pz01</td>\n",
       "      <td>NativeMotive(name='1_solution_0_rpr_A_3_G', se...</td>\n",
       "      <td>test</td>\n",
       "      <td>[{'chain': 'A', 'residue_num': 1, 'name': 'C',...</td>\n",
       "      <td>1_bujnicki_5_rpr</td>\n",
       "      <td>4.617</td>\n",
       "      <td>[{'chain': 'A', 'residue_num': 1, 'name': 'C',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34109</th>\n",
       "      <td>pz10</td>\n",
       "      <td>NativeMotive(name='10_0_solution_4LCK_rpr_B_64...</td>\n",
       "      <td>train</td>\n",
       "      <td>[{'chain': 'B', 'residue_num': 47, 'name': 'C'...</td>\n",
       "      <td>10_DING_5_rpr</td>\n",
       "      <td>2.963</td>\n",
       "      <td>[{'chain': 'B', 'residue_num': 47, 'name': 'C'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34110</th>\n",
       "      <td>pz10</td>\n",
       "      <td>NativeMotive(name='10_0_solution_4LCK_rpr_B_64...</td>\n",
       "      <td>train</td>\n",
       "      <td>[{'chain': 'B', 'residue_num': 47, 'name': 'C'...</td>\n",
       "      <td>10_DING_6_rpr</td>\n",
       "      <td>2.190</td>\n",
       "      <td>[{'chain': 'B', 'residue_num': 47, 'name': 'C'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34111</th>\n",
       "      <td>pz10</td>\n",
       "      <td>NativeMotive(name='10_0_solution_4LCK_rpr_B_64...</td>\n",
       "      <td>train</td>\n",
       "      <td>[{'chain': 'B', 'residue_num': 47, 'name': 'C'...</td>\n",
       "      <td>10_DING_7_rpr</td>\n",
       "      <td>2.374</td>\n",
       "      <td>[{'chain': 'B', 'residue_num': 47, 'name': 'C'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34112</th>\n",
       "      <td>pz10</td>\n",
       "      <td>NativeMotive(name='10_0_solution_4LCK_rpr_B_64...</td>\n",
       "      <td>train</td>\n",
       "      <td>[{'chain': 'B', 'residue_num': 47, 'name': 'C'...</td>\n",
       "      <td>10_DING_8_rpr</td>\n",
       "      <td>2.918</td>\n",
       "      <td>[{'chain': 'B', 'residue_num': 47, 'name': 'C'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34113</th>\n",
       "      <td>pz10</td>\n",
       "      <td>NativeMotive(name='10_0_solution_4LCK_rpr_B_64...</td>\n",
       "      <td>train</td>\n",
       "      <td>[{'chain': 'B', 'residue_num': 47, 'name': 'C'...</td>\n",
       "      <td>10_DING_9_rpr</td>\n",
       "      <td>2.132</td>\n",
       "      <td>[{'chain': 'B', 'residue_num': 47, 'name': 'C'...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>34114 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      puzzle                                      native_motive    set   \n",
       "0       pz01  NativeMotive(name='1_solution_0_rpr_A_3_G', se...   test  \\\n",
       "1       pz01  NativeMotive(name='1_solution_0_rpr_A_3_G', se...   test   \n",
       "2       pz01  NativeMotive(name='1_solution_0_rpr_A_3_G', se...   test   \n",
       "3       pz01  NativeMotive(name='1_solution_0_rpr_A_3_G', se...   test   \n",
       "4       pz01  NativeMotive(name='1_solution_0_rpr_A_3_G', se...   test   \n",
       "...      ...                                                ...    ...   \n",
       "34109   pz10  NativeMotive(name='10_0_solution_4LCK_rpr_B_64...  train   \n",
       "34110   pz10  NativeMotive(name='10_0_solution_4LCK_rpr_B_64...  train   \n",
       "34111   pz10  NativeMotive(name='10_0_solution_4LCK_rpr_B_64...  train   \n",
       "34112   pz10  NativeMotive(name='10_0_solution_4LCK_rpr_B_64...  train   \n",
       "34113   pz10  NativeMotive(name='10_0_solution_4LCK_rpr_B_64...  train   \n",
       "\n",
       "                                       target_tor_angles   \n",
       "0      [{'chain': 'A', 'residue_num': 1, 'name': 'C',...  \\\n",
       "1      [{'chain': 'A', 'residue_num': 1, 'name': 'C',...   \n",
       "2      [{'chain': 'A', 'residue_num': 1, 'name': 'C',...   \n",
       "3      [{'chain': 'A', 'residue_num': 1, 'name': 'C',...   \n",
       "4      [{'chain': 'A', 'residue_num': 1, 'name': 'C',...   \n",
       "...                                                  ...   \n",
       "34109  [{'chain': 'B', 'residue_num': 47, 'name': 'C'...   \n",
       "34110  [{'chain': 'B', 'residue_num': 47, 'name': 'C'...   \n",
       "34111  [{'chain': 'B', 'residue_num': 47, 'name': 'C'...   \n",
       "34112  [{'chain': 'B', 'residue_num': 47, 'name': 'C'...   \n",
       "34113  [{'chain': 'B', 'residue_num': 47, 'name': 'C'...   \n",
       "\n",
       "      prediction_motive_name   rmsd   \n",
       "0           1_bujnicki_1_rpr  4.643  \\\n",
       "1           1_bujnicki_2_rpr  4.495   \n",
       "2           1_bujnicki_3_rpr  3.862   \n",
       "3           1_bujnicki_4_rpr  4.514   \n",
       "4           1_bujnicki_5_rpr  4.617   \n",
       "...                      ...    ...   \n",
       "34109          10_DING_5_rpr  2.963   \n",
       "34110          10_DING_6_rpr  2.190   \n",
       "34111          10_DING_7_rpr  2.374   \n",
       "34112          10_DING_8_rpr  2.918   \n",
       "34113          10_DING_9_rpr  2.132   \n",
       "\n",
       "                                   nucleotide_tor_angles  \n",
       "0      [{'chain': 'A', 'residue_num': 1, 'name': 'C',...  \n",
       "1      [{'chain': 'A', 'residue_num': 1, 'name': 'C',...  \n",
       "2      [{'chain': 'A', 'residue_num': 1, 'name': 'C',...  \n",
       "3      [{'chain': 'A', 'residue_num': 1, 'name': 'C',...  \n",
       "4      [{'chain': 'A', 'residue_num': 1, 'name': 'C',...  \n",
       "...                                                  ...  \n",
       "34109  [{'chain': 'B', 'residue_num': 47, 'name': 'C'...  \n",
       "34110  [{'chain': 'B', 'residue_num': 47, 'name': 'C'...  \n",
       "34111  [{'chain': 'B', 'residue_num': 47, 'name': 'C'...  \n",
       "34112  [{'chain': 'B', 'residue_num': 47, 'name': 'C'...  \n",
       "34113  [{'chain': 'B', 'residue_num': 47, 'name': 'C'...  \n",
       "\n",
       "[34114 rows x 7 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = []\n",
    "for puzzle in motive_solutions:\n",
    "    if puzzle in ('pz01', 'pz05'):\n",
    "        set_type = 'test'\n",
    "    else:\n",
    "        set_type = 'train'\n",
    "\n",
    "    for motive in motive_solutions[puzzle]:\n",
    "        dataset.extend([dict(puzzle=puzzle, native_motive=motive_solutions[puzzle][motive]['native_motive'],\n",
    "                                set=set_type, target_tor_angles=motive_solutions[puzzle][motive]['target_tor_angles'],\n",
    "                                prediction_motive_name=motive_pred.name, rmsd=motive_pred.rmsd,\n",
    "                                nucleotide_tor_angles=motive_pred.nucleotide_tor_angles)\n",
    "                                for motive_pred in motive_solutions[puzzle][motive]['predictions']])\n",
    "\n",
    "dataset = pd.DataFrame(dataset)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9cd648bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chain</th>\n",
       "      <th>residue_num</th>\n",
       "      <th>name</th>\n",
       "      <th>alpha</th>\n",
       "      <th>beta</th>\n",
       "      <th>gamma</th>\n",
       "      <th>delta</th>\n",
       "      <th>epsilon</th>\n",
       "      <th>zeta</th>\n",
       "      <th>chi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A</td>\n",
       "      <td>1</td>\n",
       "      <td>C</td>\n",
       "      <td>NaN</td>\n",
       "      <td>176.850</td>\n",
       "      <td>44.959</td>\n",
       "      <td>91.876</td>\n",
       "      <td>-150.047</td>\n",
       "      <td>-80.396</td>\n",
       "      <td>-159.462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A</td>\n",
       "      <td>2</td>\n",
       "      <td>C</td>\n",
       "      <td>-56.496</td>\n",
       "      <td>169.031</td>\n",
       "      <td>44.356</td>\n",
       "      <td>74.273</td>\n",
       "      <td>-154.985</td>\n",
       "      <td>-76.230</td>\n",
       "      <td>-157.623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A</td>\n",
       "      <td>3</td>\n",
       "      <td>G</td>\n",
       "      <td>-69.487</td>\n",
       "      <td>177.430</td>\n",
       "      <td>52.512</td>\n",
       "      <td>77.981</td>\n",
       "      <td>-154.933</td>\n",
       "      <td>-75.264</td>\n",
       "      <td>-155.744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A</td>\n",
       "      <td>4</td>\n",
       "      <td>C</td>\n",
       "      <td>-60.263</td>\n",
       "      <td>170.927</td>\n",
       "      <td>42.313</td>\n",
       "      <td>81.796</td>\n",
       "      <td>-154.333</td>\n",
       "      <td>-69.952</td>\n",
       "      <td>-160.246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A</td>\n",
       "      <td>5</td>\n",
       "      <td>C</td>\n",
       "      <td>-77.439</td>\n",
       "      <td>179.135</td>\n",
       "      <td>59.432</td>\n",
       "      <td>76.937</td>\n",
       "      <td>-144.338</td>\n",
       "      <td>-78.585</td>\n",
       "      <td>-159.848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>A</td>\n",
       "      <td>6</td>\n",
       "      <td>G</td>\n",
       "      <td>-62.513</td>\n",
       "      <td>161.032</td>\n",
       "      <td>58.492</td>\n",
       "      <td>81.831</td>\n",
       "      <td>-150.465</td>\n",
       "      <td>-79.457</td>\n",
       "      <td>-169.419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>A</td>\n",
       "      <td>7</td>\n",
       "      <td>C</td>\n",
       "      <td>-47.744</td>\n",
       "      <td>165.734</td>\n",
       "      <td>42.144</td>\n",
       "      <td>87.830</td>\n",
       "      <td>-152.870</td>\n",
       "      <td>-72.211</td>\n",
       "      <td>-155.851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>A</td>\n",
       "      <td>8</td>\n",
       "      <td>G</td>\n",
       "      <td>-64.037</td>\n",
       "      <td>175.025</td>\n",
       "      <td>49.996</td>\n",
       "      <td>81.011</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-161.947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>B</td>\n",
       "      <td>10</td>\n",
       "      <td>C</td>\n",
       "      <td>NaN</td>\n",
       "      <td>172.832</td>\n",
       "      <td>56.562</td>\n",
       "      <td>76.467</td>\n",
       "      <td>-151.416</td>\n",
       "      <td>-69.533</td>\n",
       "      <td>-162.329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>B</td>\n",
       "      <td>11</td>\n",
       "      <td>A</td>\n",
       "      <td>-69.710</td>\n",
       "      <td>169.654</td>\n",
       "      <td>65.485</td>\n",
       "      <td>78.423</td>\n",
       "      <td>-158.423</td>\n",
       "      <td>-67.656</td>\n",
       "      <td>-169.968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>B</td>\n",
       "      <td>12</td>\n",
       "      <td>U</td>\n",
       "      <td>-78.528</td>\n",
       "      <td>-176.854</td>\n",
       "      <td>55.772</td>\n",
       "      <td>72.066</td>\n",
       "      <td>-149.076</td>\n",
       "      <td>-72.637</td>\n",
       "      <td>-155.245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>B</td>\n",
       "      <td>13</td>\n",
       "      <td>G</td>\n",
       "      <td>-68.925</td>\n",
       "      <td>162.692</td>\n",
       "      <td>55.286</td>\n",
       "      <td>75.753</td>\n",
       "      <td>-149.107</td>\n",
       "      <td>-73.536</td>\n",
       "      <td>-164.976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>B</td>\n",
       "      <td>14</td>\n",
       "      <td>C</td>\n",
       "      <td>-66.840</td>\n",
       "      <td>166.906</td>\n",
       "      <td>59.172</td>\n",
       "      <td>78.067</td>\n",
       "      <td>-159.462</td>\n",
       "      <td>-68.839</td>\n",
       "      <td>-156.695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>B</td>\n",
       "      <td>15</td>\n",
       "      <td>C</td>\n",
       "      <td>-70.041</td>\n",
       "      <td>-170.136</td>\n",
       "      <td>43.880</td>\n",
       "      <td>93.949</td>\n",
       "      <td>-117.598</td>\n",
       "      <td>-140.651</td>\n",
       "      <td>-134.882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>B</td>\n",
       "      <td>16</td>\n",
       "      <td>U</td>\n",
       "      <td>47.916</td>\n",
       "      <td>-141.478</td>\n",
       "      <td>46.468</td>\n",
       "      <td>96.303</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-130.070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>B</td>\n",
       "      <td>19</td>\n",
       "      <td>G</td>\n",
       "      <td>NaN</td>\n",
       "      <td>176.151</td>\n",
       "      <td>53.167</td>\n",
       "      <td>70.713</td>\n",
       "      <td>-161.719</td>\n",
       "      <td>-51.669</td>\n",
       "      <td>-169.119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>B</td>\n",
       "      <td>20</td>\n",
       "      <td>G</td>\n",
       "      <td>-79.167</td>\n",
       "      <td>-172.773</td>\n",
       "      <td>60.955</td>\n",
       "      <td>75.185</td>\n",
       "      <td>-143.060</td>\n",
       "      <td>-77.320</td>\n",
       "      <td>-161.701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>B</td>\n",
       "      <td>21</td>\n",
       "      <td>C</td>\n",
       "      <td>-64.912</td>\n",
       "      <td>154.109</td>\n",
       "      <td>64.869</td>\n",
       "      <td>69.667</td>\n",
       "      <td>-152.374</td>\n",
       "      <td>-67.037</td>\n",
       "      <td>-163.122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>B</td>\n",
       "      <td>22</td>\n",
       "      <td>G</td>\n",
       "      <td>-72.341</td>\n",
       "      <td>171.819</td>\n",
       "      <td>54.834</td>\n",
       "      <td>80.379</td>\n",
       "      <td>-153.256</td>\n",
       "      <td>-73.312</td>\n",
       "      <td>-166.103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>B</td>\n",
       "      <td>23</td>\n",
       "      <td>G</td>\n",
       "      <td>-64.487</td>\n",
       "      <td>171.425</td>\n",
       "      <td>60.480</td>\n",
       "      <td>83.291</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-160.436</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   chain  residue_num name   alpha     beta   gamma   delta  epsilon     zeta   \n",
       "0      A            1    C     NaN  176.850  44.959  91.876 -150.047  -80.396  \\\n",
       "1      A            2    C -56.496  169.031  44.356  74.273 -154.985  -76.230   \n",
       "2      A            3    G -69.487  177.430  52.512  77.981 -154.933  -75.264   \n",
       "3      A            4    C -60.263  170.927  42.313  81.796 -154.333  -69.952   \n",
       "4      A            5    C -77.439  179.135  59.432  76.937 -144.338  -78.585   \n",
       "5      A            6    G -62.513  161.032  58.492  81.831 -150.465  -79.457   \n",
       "6      A            7    C -47.744  165.734  42.144  87.830 -152.870  -72.211   \n",
       "7      A            8    G -64.037  175.025  49.996  81.011      NaN      NaN   \n",
       "8      B           10    C     NaN  172.832  56.562  76.467 -151.416  -69.533   \n",
       "9      B           11    A -69.710  169.654  65.485  78.423 -158.423  -67.656   \n",
       "10     B           12    U -78.528 -176.854  55.772  72.066 -149.076  -72.637   \n",
       "11     B           13    G -68.925  162.692  55.286  75.753 -149.107  -73.536   \n",
       "12     B           14    C -66.840  166.906  59.172  78.067 -159.462  -68.839   \n",
       "13     B           15    C -70.041 -170.136  43.880  93.949 -117.598 -140.651   \n",
       "14     B           16    U  47.916 -141.478  46.468  96.303      NaN      NaN   \n",
       "15     B           19    G     NaN  176.151  53.167  70.713 -161.719  -51.669   \n",
       "16     B           20    G -79.167 -172.773  60.955  75.185 -143.060  -77.320   \n",
       "17     B           21    C -64.912  154.109  64.869  69.667 -152.374  -67.037   \n",
       "18     B           22    G -72.341  171.819  54.834  80.379 -153.256  -73.312   \n",
       "19     B           23    G -64.487  171.425  60.480  83.291      NaN      NaN   \n",
       "\n",
       "        chi  \n",
       "0  -159.462  \n",
       "1  -157.623  \n",
       "2  -155.744  \n",
       "3  -160.246  \n",
       "4  -159.848  \n",
       "5  -169.419  \n",
       "6  -155.851  \n",
       "7  -161.947  \n",
       "8  -162.329  \n",
       "9  -169.968  \n",
       "10 -155.245  \n",
       "11 -164.976  \n",
       "12 -156.695  \n",
       "13 -134.882  \n",
       "14 -130.070  \n",
       "15 -169.119  \n",
       "16 -161.701  \n",
       "17 -163.122  \n",
       "18 -166.103  \n",
       "19 -160.436  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_tor_angles_example_df = pd.DataFrame(dataset['target_tor_angles'].iloc[23])\n",
    "nucleotide_tor_angles_example_df = pd.DataFrame(dataset['nucleotide_tor_angles'].iloc[23])\n",
    "target_tor_angles_example_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "4e5b34d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset size: 24634 0.7221082253620215\n",
      "Validation dataset size: 4348 0.12745500381075217\n",
      "Test dataset size: 5132 0.15043677082722637\n"
     ]
    }
   ],
   "source": [
    "# Split the data into training, validation, test sets\n",
    "train_ds, test_ds = dataset[dataset.set == 'train'], dataset[dataset.set == 'test']\n",
    "train_ds, valid_ds = train_test_split(train_ds, test_size=0.15, random_state=42)\n",
    "valid_ds.set = 'valid'\n",
    "print(\"Training dataset size:\", train_ds.shape[0], train_ds.shape[0] / dataset.shape[0])\n",
    "print(\"Validation dataset size:\", valid_ds.shape[0], valid_ds.shape[0] / dataset.shape[0])\n",
    "print(\"Test dataset size:\", test_ds.shape[0], test_ds.shape[0] / dataset.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9331606c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoder-Decoder with Attention\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, hidden_size=4, tor_features=11):\n",
    "        super().__init__()\n",
    "        self.rnn = nn.GRU(input_size=tor_features, hidden_size=hidden_size, bidirectional = True)\n",
    "        \n",
    "    def forward(self, src, src_len):\n",
    "        packed_outputs = nn.utils.rnn.pack_padded_sequence(src, src_len, enforce_sorted=False)\n",
    "        packed_outputs, hidden = self.rnn(packed_outputs)   \n",
    "        outputs, _ = nn.utils.rnn.pad_packed_sequence(packed_outputs)\n",
    "        hidden = torch.cat([hidden[0,:, :], hidden[1,:,:]], dim=1)\n",
    "        return outputs, hidden.unsqueeze(0)\n",
    "    \n",
    "class DecoderWithAttention(nn.Module):\n",
    "    def __init__(self, hidden_size=8, tor_features=11):\n",
    "        super().__init__()\n",
    "        self.input_size = tor_features\n",
    "        self.rnn = nn.GRU(input_size=hidden_size+tor_features, hidden_size=hidden_size)\n",
    "        self.lin1 = nn.Linear(hidden_size, hidden_size//2)\n",
    "        self.lin2 = nn.Linear(hidden_size//2, 1)\n",
    "        self.fc = nn.Sequential(self.lin1, nn.ReLU(), self.lin2)\n",
    "        \n",
    "    \n",
    "    def forward(self, input, hidden, encoder_outputs):\n",
    "        \n",
    "        # input = [batch size]\n",
    "        # hidden = [batch size, hidden_size]\n",
    "        # encoder_outputs = [src len, batch size, hidden_size]\n",
    "        # mask = [batch size, src len]\n",
    "        \n",
    "\n",
    "        # context = [batch size, hidden_size]\n",
    "        attention_weights = torch.bmm(hidden.permute(1, 0, 2), encoder_outputs.permute(1, 2, 0)).softmax(2).to(input.device)\n",
    "        context = torch.bmm(attention_weights, encoder_outputs.permute(1, 0, 2)).squeeze(1).to(input.device)\n",
    "        \n",
    "        #Wejście do sieci do wektor kontekstu połączony z przetwarzanym słowem\n",
    "        # print(input.shape, context.shape)\n",
    "        rnn_input = torch.cat((input, context), dim = 1)\n",
    "        \n",
    "        # Wejście do sieci rekurencyjnej zawiera wymiar - długość przetwarzanej sekwencji\n",
    "        # Konieczne jest więc \"sztuczne\" dodanie wymiaru na pierwszej (tj. zerowej) pozycji\n",
    "        rnn_input = rnn_input.unsqueeze(0)\n",
    "        #rnn_input = [1, batch size, word_embedding + hidden_size]\n",
    "        \n",
    "        _, hidden = self.rnn(rnn_input, hidden)\n",
    "        \n",
    "        prediction = self.fc(hidden.squeeze(0))\n",
    "        \n",
    "        return prediction, hidden\n",
    "\n",
    "class EncoderDecoder(nn.Module):\n",
    "    def __init__(self, encoder, decoder):\n",
    "        super().__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.device = next(encoder.parameters()).device\n",
    "        \n",
    "    def forward(self, src, tgt, src_len, batch_size):       \n",
    "        tgt_len = tgt.shape[0]\n",
    "        \n",
    "        # tensor to store decoder outputs\n",
    "        outputs = torch.zeros(tgt_len, batch_size, 1).to(self.device)\n",
    "        \n",
    "        # Przetworzenie wejścia przez koder, kolejno uzyskane reprezentacje\n",
    "        # kazdego słowa będą potrzebne do implementacji mechanizmu uwagi\n",
    "        # Z kolei hidden posłuży do inicjalizacji stanu ukrytego dekodera\n",
    "        encoder_outputs, hidden = self.encoder(src, src_len)\n",
    "        \n",
    "        #first input to the decoder is the <sos> tokens\n",
    "        prev_target = tgt[0, :]\n",
    "                \n",
    "        for i in range(1, tgt_len):\n",
    "            output, hidden = self.decoder(prev_target, hidden, encoder_outputs)\n",
    "            outputs[i] = output\n",
    "               \n",
    "            # uczenie poprzez teaching forcing\n",
    "            prev_target = tgt[i] # if self.training else output.argmax(1)\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "dbd7d75f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_tor_data(tor_df: pd.DataFrame) -> pd.DataFrame:\n",
    "    tor_df = tor_df.drop(['chain', 'residue_num'], axis=1)\n",
    "\n",
    "    cols_to_normalize = [col for col in tor_df.columns if col != 'name']\n",
    "    scaler = MinMaxScaler()\n",
    "    tor_df[cols_to_normalize] = scaler.fit_transform(tor_df[cols_to_normalize])\n",
    "    imp = SimpleImputer(missing_values=np.nan, strategy='median')\n",
    "    tor_df[cols_to_normalize] = imp.fit_transform(tor_df[cols_to_normalize])\n",
    "\n",
    "    # One hot encoding\n",
    "    for nuc in 'ACUG':\n",
    "        # tor_df[f'target_name_{nuc}'] = tor_df['target_name'].apply(str).str.contains(nuc).astype(int)\n",
    "        tor_df[f'name_{nuc}'] = tor_df['name'].apply(str).str.contains(nuc).astype(int)\n",
    "\n",
    "    tor_df = tor_df.drop(['name'], axis=1)\n",
    "    return tor_df\n",
    "\n",
    "def shuffle_batches(permutation, batch_size, x_len):\n",
    "    batch_count = int(x_len // batch_size)\n",
    "    result = [permutation[batch_idx*batch_size:(batch_idx+1)*batch_size] for batch_idx in range(batch_count)]\n",
    "    return result\n",
    "\n",
    "def create_batch(dataset, indxs, device):\n",
    "    \n",
    "    x1 = [torch.tensor(preprocess_tor_data(pd.DataFrame(dataset.iloc[i.item()]['target_tor_angles'])).\n",
    "                       to_numpy()).to(device) for i in indxs]\n",
    "    x2 = [torch.tensor(preprocess_tor_data(pd.DataFrame(dataset.iloc[i.item()]['nucleotide_tor_angles']))\n",
    "                       .to_numpy()).to(device) for i in indxs]\n",
    "    src_batch = pad_sequence(x2, padding_value=0).float().to(device)\n",
    "    tgt_batch = pad_sequence(x1, padding_value=0).float().to(device)\n",
    "\n",
    "    # x1 = pack_sequence(x1, enforce_sorted=False).float().to(device)\n",
    "    # x2 = pack_sequence(x2, enforce_sorted=False).float().to(device)\n",
    "    len_src_batch = torch.tensor([len(x) for x in x2], dtype=torch.int64)\n",
    "    len_tgt_batch = torch.tensor([len(x) for x in x1], dtype=torch.int64)\n",
    "    y = torch.tensor([dataset.iloc[i.item()]['rmsd'] for i in indxs]).float().unsqueeze(1).to(device)\n",
    "    return src_batch, tgt_batch, y, len_src_batch, len_tgt_batch\n",
    "\n",
    "epochs = 8\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c4cca1ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alpha</th>\n",
       "      <th>beta</th>\n",
       "      <th>gamma</th>\n",
       "      <th>delta</th>\n",
       "      <th>epsilon</th>\n",
       "      <th>zeta</th>\n",
       "      <th>chi</th>\n",
       "      <th>name_A</th>\n",
       "      <th>name_C</th>\n",
       "      <th>name_U</th>\n",
       "      <th>name_G</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.097000</td>\n",
       "      <td>0.993581</td>\n",
       "      <td>0.120603</td>\n",
       "      <td>0.833796</td>\n",
       "      <td>0.264545</td>\n",
       "      <td>0.677159</td>\n",
       "      <td>0.263321</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.178395</td>\n",
       "      <td>0.971617</td>\n",
       "      <td>0.094769</td>\n",
       "      <td>0.172924</td>\n",
       "      <td>0.152626</td>\n",
       "      <td>0.723978</td>\n",
       "      <td>0.309414</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.076171</td>\n",
       "      <td>0.995211</td>\n",
       "      <td>0.444197</td>\n",
       "      <td>0.312134</td>\n",
       "      <td>0.153804</td>\n",
       "      <td>0.734834</td>\n",
       "      <td>0.356509</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.148753</td>\n",
       "      <td>0.976943</td>\n",
       "      <td>0.007240</td>\n",
       "      <td>0.455361</td>\n",
       "      <td>0.167403</td>\n",
       "      <td>0.794531</td>\n",
       "      <td>0.243671</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.013597</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.740671</td>\n",
       "      <td>0.272939</td>\n",
       "      <td>0.393939</td>\n",
       "      <td>0.697512</td>\n",
       "      <td>0.253647</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.131048</td>\n",
       "      <td>0.949147</td>\n",
       "      <td>0.700398</td>\n",
       "      <td>0.456675</td>\n",
       "      <td>0.255071</td>\n",
       "      <td>0.687712</td>\n",
       "      <td>0.013760</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.247264</td>\n",
       "      <td>0.962356</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.681897</td>\n",
       "      <td>0.200562</td>\n",
       "      <td>0.769144</td>\n",
       "      <td>0.353827</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.119056</td>\n",
       "      <td>0.988455</td>\n",
       "      <td>0.336404</td>\n",
       "      <td>0.425890</td>\n",
       "      <td>0.211804</td>\n",
       "      <td>0.756771</td>\n",
       "      <td>0.201038</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.097000</td>\n",
       "      <td>0.982294</td>\n",
       "      <td>0.617711</td>\n",
       "      <td>0.255294</td>\n",
       "      <td>0.233517</td>\n",
       "      <td>0.799240</td>\n",
       "      <td>0.191463</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.074416</td>\n",
       "      <td>0.973367</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.328728</td>\n",
       "      <td>0.074704</td>\n",
       "      <td>0.820334</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.005028</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.583865</td>\n",
       "      <td>0.090066</td>\n",
       "      <td>0.286553</td>\n",
       "      <td>0.764357</td>\n",
       "      <td>0.369016</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.080593</td>\n",
       "      <td>0.953810</td>\n",
       "      <td>0.563044</td>\n",
       "      <td>0.228488</td>\n",
       "      <td>0.285850</td>\n",
       "      <td>0.754254</td>\n",
       "      <td>0.125119</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.097000</td>\n",
       "      <td>0.965648</td>\n",
       "      <td>0.729532</td>\n",
       "      <td>0.315363</td>\n",
       "      <td>0.051155</td>\n",
       "      <td>0.807040</td>\n",
       "      <td>0.332673</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.071811</td>\n",
       "      <td>0.018871</td>\n",
       "      <td>0.074376</td>\n",
       "      <td>0.911623</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.879392</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.099374</td>\n",
       "      <td>0.185253</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.211804</td>\n",
       "      <td>0.756771</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.097000</td>\n",
       "      <td>0.991618</td>\n",
       "      <td>0.472259</td>\n",
       "      <td>0.039270</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.021279</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.011464</td>\n",
       "      <td>0.805921</td>\n",
       "      <td>0.207163</td>\n",
       "      <td>0.422905</td>\n",
       "      <td>0.711728</td>\n",
       "      <td>0.207203</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.112171</td>\n",
       "      <td>0.929700</td>\n",
       "      <td>0.973609</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.211804</td>\n",
       "      <td>0.827291</td>\n",
       "      <td>0.171588</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.053713</td>\n",
       "      <td>0.979449</td>\n",
       "      <td>0.543679</td>\n",
       "      <td>0.402162</td>\n",
       "      <td>0.191813</td>\n",
       "      <td>0.756771</td>\n",
       "      <td>0.096872</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.115515</td>\n",
       "      <td>0.978342</td>\n",
       "      <td>0.785570</td>\n",
       "      <td>0.511488</td>\n",
       "      <td>0.211804</td>\n",
       "      <td>0.756771</td>\n",
       "      <td>0.238909</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       alpha      beta     gamma     delta   epsilon      zeta       chi   \n",
       "0   0.097000  0.993581  0.120603  0.833796  0.264545  0.677159  0.263321  \\\n",
       "1   0.178395  0.971617  0.094769  0.172924  0.152626  0.723978  0.309414   \n",
       "2   0.076171  0.995211  0.444197  0.312134  0.153804  0.734834  0.356509   \n",
       "3   0.148753  0.976943  0.007240  0.455361  0.167403  0.794531  0.243671   \n",
       "4   0.013597  1.000000  0.740671  0.272939  0.393939  0.697512  0.253647   \n",
       "5   0.131048  0.949147  0.700398  0.456675  0.255071  0.687712  0.013760   \n",
       "6   0.247264  0.962356  0.000000  0.681897  0.200562  0.769144  0.353827   \n",
       "7   0.119056  0.988455  0.336404  0.425890  0.211804  0.756771  0.201038   \n",
       "8   0.097000  0.982294  0.617711  0.255294  0.233517  0.799240  0.191463   \n",
       "9   0.074416  0.973367  1.000000  0.328728  0.074704  0.820334  0.000000   \n",
       "10  0.005028  0.000000  0.583865  0.090066  0.286553  0.764357  0.369016   \n",
       "11  0.080593  0.953810  0.563044  0.228488  0.285850  0.754254  0.125119   \n",
       "12  0.097000  0.965648  0.729532  0.315363  0.051155  0.807040  0.332673   \n",
       "13  0.071811  0.018871  0.074376  0.911623  1.000000  0.000000  0.879392   \n",
       "14  1.000000  0.099374  0.185253  1.000000  0.211804  0.756771  1.000000   \n",
       "15  0.097000  0.991618  0.472259  0.039270  0.000000  1.000000  0.021279   \n",
       "16  0.000000  0.011464  0.805921  0.207163  0.422905  0.711728  0.207203   \n",
       "17  0.112171  0.929700  0.973609  0.000000  0.211804  0.827291  0.171588   \n",
       "18  0.053713  0.979449  0.543679  0.402162  0.191813  0.756771  0.096872   \n",
       "19  0.115515  0.978342  0.785570  0.511488  0.211804  0.756771  0.238909   \n",
       "\n",
       "    name_A  name_C  name_U  name_G  \n",
       "0        0       1       0       0  \n",
       "1        0       1       0       0  \n",
       "2        0       0       0       1  \n",
       "3        0       1       0       0  \n",
       "4        0       1       0       0  \n",
       "5        0       0       0       1  \n",
       "6        0       1       0       0  \n",
       "7        0       0       0       1  \n",
       "8        0       1       0       0  \n",
       "9        1       0       0       0  \n",
       "10       0       0       1       0  \n",
       "11       0       0       0       1  \n",
       "12       0       1       0       0  \n",
       "13       0       1       0       0  \n",
       "14       0       0       1       0  \n",
       "15       0       0       0       1  \n",
       "16       0       0       0       1  \n",
       "17       0       1       0       0  \n",
       "18       0       0       0       1  \n",
       "19       0       0       0       1  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_tor_df = preprocess_tor_data(target_tor_angles_example_df)\n",
    "example_tor_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "cc1f92f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start learning\n",
      "Running training loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 1:   4%|▎         | 9/249 [00:27<12:12,  3.05s/batch, train_loss=118] \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[39], line 24\u001b[0m\n\u001b[0;32m     22\u001b[0m p_bar\u001b[38;5;241m.\u001b[39mset_description(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     23\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m---> 24\u001b[0m src, tgt, y, src_len, tgt_len \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_ds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midxs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     26\u001b[0m outputs \u001b[38;5;241m=\u001b[39m enc_dec(src, tgt, src_len, batch_size)\n\u001b[0;32m     27\u001b[0m \u001b[38;5;66;03m# Token START nie jest przewidywany przez dekoder\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[37], line 27\u001b[0m, in \u001b[0;36mcreate_batch\u001b[1;34m(dataset, indxs, device)\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate_batch\u001b[39m(dataset, indxs, device):\n\u001b[0;32m     25\u001b[0m     x1 \u001b[38;5;241m=\u001b[39m [torch\u001b[38;5;241m.\u001b[39mtensor(preprocess_tor_data(pd\u001b[38;5;241m.\u001b[39mDataFrame(dataset\u001b[38;5;241m.\u001b[39miloc[i\u001b[38;5;241m.\u001b[39mitem()][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtarget_tor_angles\u001b[39m\u001b[38;5;124m'\u001b[39m]))\u001b[38;5;241m.\u001b[39m\n\u001b[0;32m     26\u001b[0m                        to_numpy())\u001b[38;5;241m.\u001b[39mto(device) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m indxs]\n\u001b[1;32m---> 27\u001b[0m     x2 \u001b[38;5;241m=\u001b[39m \u001b[43m[\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpreprocess_tor_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataFrame\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mnucleotide_tor_angles\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     28\u001b[0m \u001b[43m                       \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_numpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mindxs\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m     29\u001b[0m     src_batch \u001b[38;5;241m=\u001b[39m pad_sequence(x2, padding_value\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mfloat()\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     30\u001b[0m     tgt_batch \u001b[38;5;241m=\u001b[39m pad_sequence(x1, padding_value\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mfloat()\u001b[38;5;241m.\u001b[39mto(device)\n",
      "Cell \u001b[1;32mIn[37], line 28\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate_batch\u001b[39m(dataset, indxs, device):\n\u001b[0;32m     25\u001b[0m     x1 \u001b[38;5;241m=\u001b[39m [torch\u001b[38;5;241m.\u001b[39mtensor(preprocess_tor_data(pd\u001b[38;5;241m.\u001b[39mDataFrame(dataset\u001b[38;5;241m.\u001b[39miloc[i\u001b[38;5;241m.\u001b[39mitem()][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtarget_tor_angles\u001b[39m\u001b[38;5;124m'\u001b[39m]))\u001b[38;5;241m.\u001b[39m\n\u001b[0;32m     26\u001b[0m                        to_numpy())\u001b[38;5;241m.\u001b[39mto(device) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m indxs]\n\u001b[0;32m     27\u001b[0m     x2 \u001b[38;5;241m=\u001b[39m [\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpreprocess_tor_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataFrame\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mnucleotide_tor_angles\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m---> 28\u001b[0m \u001b[43m                       \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_numpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m indxs]\n\u001b[0;32m     29\u001b[0m     src_batch \u001b[38;5;241m=\u001b[39m pad_sequence(x2, padding_value\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mfloat()\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     30\u001b[0m     tgt_batch \u001b[38;5;241m=\u001b[39m pad_sequence(x1, padding_value\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mfloat()\u001b[38;5;241m.\u001b[39mto(device)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print(\"Start learning\")\n",
    "train_history, valid_history = [], []\n",
    "train_batch = 0\n",
    "enc = Encoder().to(device)\n",
    "dec = DecoderWithAttention().to(device)\n",
    "enc_dec = EncoderDecoder(enc, dec).to(device)\n",
    "\n",
    "lr = 0.001\n",
    "optimizer = torch.optim.Adam(enc_dec.parameters(), lr=lr)\n",
    "\n",
    "epochs = 8\n",
    "batch_size = 128\n",
    "loss_fn = nn.MSELoss()\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print(\"Running training loop\")\n",
    "    enc_dec.train()\n",
    "    batches = shuffle_batches(torch.randperm(train_ds.shape[0]), batch_size, train_ds.shape[0])\n",
    "    train_losses = []\n",
    "    p_bar = tqdm(batches, unit='batch')\n",
    "    for idxs in p_bar:\n",
    "        p_bar.set_description(f\"Epoch: {epoch + 1}\")\n",
    "        optimizer.zero_grad()\n",
    "        src, tgt, y, src_len, tgt_len = create_batch(train_ds, idxs, device)\n",
    "        \n",
    "        outputs = enc_dec(src, tgt, src_len, batch_size)\n",
    "        # Token START nie jest przewidywany przez dekoder\n",
    "        tgt = tgt[1:].view(-1)\n",
    "\n",
    "        # Tablekę outputs zaczęliśmy uzupełniać od indeksu 1\n",
    "        outputs = outputs[-1].view(-1, 1)\n",
    "\n",
    "        # print(outputs.shape)\n",
    "        # print(y.shape)\n",
    "\n",
    "        loss = loss_fn(outputs, y)\n",
    "        loss.backward()\n",
    "\n",
    "        # Ucinanie gradientu\n",
    "        torch.nn.utils.clip_grad_norm_(enc_dec.parameters(), 2.)\n",
    "        \n",
    "        optimizer.step()\n",
    "        train_losses.append(loss.item())\n",
    "        train_loss = np.mean(train_losses)\n",
    "        p_bar.set_postfix(train_loss=train_loss)\n",
    "        train_history.append(dict(epoch=epoch, batch=train_batch, batch_loss=loss.item()))\n",
    "        train_batch += 1\n",
    "    \n",
    "    print(\"Running validation loop\")\n",
    "    enc_dec.eval()\n",
    "    \n",
    "\n",
    "    with torch.no_grad():\n",
    "        batches = shuffle_batches(torch.randperm(valid_ds.shape[0]), batch_size, valid_ds.shape[0])\n",
    "        p_bar = tqdm(batches, unit='batch')\n",
    "        for idxs in p_bar:\n",
    "            p_bar.set_description(f\"Epoch: {epoch + 1}\")\n",
    "            src, tgt, y, src_len, tgt_len = create_batch(valid_ds, idxs, device)\n",
    "            y_pred = enc_dec(src, tgt, src_len, batch_size)\n",
    "            y_pred = y_pred[-1].view(-1, 1)\n",
    "            valid_loss = loss_fn(y_pred, y).item()\n",
    "            valid_rmse = ((y_pred - y)**2).mean().sqrt().item()\n",
    "\n",
    "            p_bar.set_postfix(valid_loss=valid_loss, valid_rmse=valid_rmse)\n",
    "            valid_history.append(dict(epoch=epoch, train_loss=train_loss, valid_loss=valid_loss, valid_rmse=valid_rmse))\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3fd2ffab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start testing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch: 4: 100%|██████████| 4/4 [00:11<00:00,  2.97s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 torch.Size([128, 1])\n",
      "4 torch.Size([128, 1])\n",
      "tensor([[0.2093],\n",
      "        [0.2259],\n",
      "        [0.2258],\n",
      "        [0.2127]], device='cuda:0')\n",
      "tensor([[3.2290],\n",
      "        [4.3010],\n",
      "        [4.0890],\n",
      "        [3.4750]], device='cuda:0')\n",
      "Test RMSE: 3.42314\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Start testing\")\n",
    "enc_dec.eval()\n",
    "preds, values = [], []\n",
    "with torch.no_grad():\n",
    "    batches = shuffle_batches(torch.randperm(test_ds.shape[0]), batch_size, test_ds.shape[0])\n",
    "    p_bar = tqdm(batches, unit='batch')\n",
    "    for batch_idx, idxs in enumerate(p_bar):\n",
    "        p_bar.set_description(f\"Batch: {batch_idx + 1}\")\n",
    "        src, tgt, y, src_len, tgt_len = create_batch(test_ds, idxs, device)\n",
    "        y_pred = enc_dec(src, tgt, src_len, batch_size)\n",
    "        y_pred = y_pred[-1].view(-1, 1)\n",
    "        preds.append(y_pred)\n",
    "        values.append(y)\n",
    "print(len(preds), preds[0].shape)\n",
    "print(len(values), values[0].shape)\n",
    "print(preds[0][-4:])\n",
    "print(values[0][-4:])\n",
    "preds, values = torch.cat(preds).detach().cpu().numpy(), torch.cat(values).detach().cpu().numpy()\n",
    "test_rmse = np.sqrt(((preds - values) ** 2).mean())\n",
    "\n",
    "print(\"Test RMSE:\", test_rmse)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
