{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7a9r0hf2tOgi",
        "outputId": "9ba0928b-fe83-4fb8-ff03-6f5233bb89c6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'UFold'...\n",
            "remote: Enumerating objects: 296, done.\u001b[K\n",
            "remote: Counting objects: 100% (140/140), done.\u001b[K\n",
            "remote: Compressing objects: 100% (44/44), done.\u001b[K\n",
            "remote: Total 296 (delta 129), reused 96 (delta 96), pack-reused 156\u001b[K\n",
            "Receiving objects: 100% (296/296), 503.24 KiB | 6.54 MiB/s, done.\n",
            "Resolving deltas: 100% (167/167), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/Michu-dev/UFold"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kmR1gfhFuhGh",
        "outputId": "1635239b-cb83-44e9-d908-360967e48f81"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "unzip:  cannot find or open SIwB-lab-06-data.zip, SIwB-lab-06-data.zip.zip or SIwB-lab-06-data.zip.ZIP.\n"
          ]
        }
      ],
      "source": [
        "!unzip SIwB-lab-06-data.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "35zdEE1KujPG"
      },
      "outputs": [],
      "source": [
        "!mkdir UFold/data/ArchiveII_bpseq \\\n",
        "UFold/data/PDB_bpseq"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VUGbSBItu1hP"
      },
      "outputs": [],
      "source": [
        "!cp ArchiveII/*.bpseq UFold/data/ArchiveII_bpseq"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EnMLRna6u8Xk"
      },
      "outputs": [],
      "source": [
        "!cp PDB/*.bpseq UFold/data/PDB_bpseq"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BcamZ80bvLGB"
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "import shutil\n",
        "\n",
        "def split_directory(directory_path, data_fraction=0.1):\n",
        "    # Create subdirectories\n",
        "    subdirectories = [directory_path / \"train\", directory_path / \"test\", directory_path / \"valid\"]\n",
        "    for subdirectory in subdirectories:\n",
        "        subdirectory.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    # Iterate through files in the directory\n",
        "    for i, file_path in enumerate(directory_path.iterdir()):\n",
        "        if file_path.is_file():\n",
        "            # Calculate the modulo result\n",
        "            modulo_result = i % (5 / data_fraction)\n",
        "\n",
        "            # Determine the target subdirectory based on the modulo result\n",
        "            if modulo_result in [0, 1, 2]:\n",
        "                target_subdirectory = subdirectories[0]\n",
        "            elif modulo_result == 3:\n",
        "                target_subdirectory = subdirectories[1]\n",
        "            elif modulo_result == 4:\n",
        "                target_subdirectory = subdirectories[2]\n",
        "            else:\n",
        "              continue\n",
        "\n",
        "            # Move the file to the target subdirectory\n",
        "            shutil.move(str(file_path), str(target_subdirectory))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sFsE2t42vMw8"
      },
      "outputs": [],
      "source": [
        "directory_path = Path('UFold/data/PDB_bpseq')\n",
        "split_directory(directory_path, 1)\n",
        "\n",
        "directory_path = Path('UFold/data/ArchiveII_bpseq')\n",
        "split_directory(directory_path, 0.1)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print (len(list(Path('UFold/data/PDB_bpseq/test').glob('*'))))\n",
        "print (len(list(Path('UFold/data/PDB_bpseq/valid').glob('*'))))\n",
        "print (len(list(Path('UFold/data/PDB_bpseq/train').glob('*'))))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0EUGCwDtrwr1",
        "outputId": "711f76cf-86c1-4f32-c291-53740acf7b1b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "119\n",
            "118\n",
            "357\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print (len(list(Path('UFold/data/ArchiveII_bpseq/test').glob('*'))))\n",
        "print (len(list(Path('UFold/data/ArchiveII_bpseq/valid').glob('*'))))\n",
        "print (len(list(Path('UFold/data/ArchiveII_bpseq/train').glob('*'))))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L57TO4Pkr5U-",
        "outputId": "8abb8761-8be5-4a49-adc9-0a0b18c89ada"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "80\n",
            "80\n",
            "240\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LPex38rSvaEA",
        "outputId": "b8a14a85-e54c-4a80-817b-3a133e0dcc56"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "current processing 1/240\n",
            "235\n",
            "current processing 1/80\n",
            "79\n",
            "current processing 1/80\n",
            "80\n"
          ]
        }
      ],
      "source": [
        "!cd UFold && python process_data_newdataset.py data/ArchiveII_bpseq/train data/ArchiveII_train.cPickle\n",
        "!cd UFold && python process_data_newdataset.py data/ArchiveII_bpseq/test data/ArchiveII_test.cPickle\n",
        "!cd UFold && python process_data_newdataset.py data/ArchiveII_bpseq/valid data/ArchiveII_valid.cPickle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vb_jsYHW9f0J",
        "outputId": "82e152af-d6a1-4299-a954-4e4b9df1b05c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "current processing 1/357\n",
            "332\n",
            "current processing 1/119\n",
            "112\n",
            "current processing 1/118\n",
            "104\n"
          ]
        }
      ],
      "source": [
        "!cd UFold && python process_data_newdataset.py data/PDB_bpseq/train data/PDB_train.cPickle\n",
        "!cd UFold && python process_data_newdataset.py data/PDB_bpseq/test data/PDB_test.cPickle\n",
        "!cd UFold && python process_data_newdataset.py data/PDB_bpseq/valid data/PDB_valid.cPickle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IqiWFQgr8RlC",
        "outputId": "106e7889-f1e5-4258-fbd9-9d92bdaa6d33"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting munch==2.5.0\n",
            "  Downloading munch-2.5.0-py2.py3-none-any.whl (10 kB)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from munch==2.5.0) (1.16.0)\n",
            "Installing collected packages: munch\n",
            "Successfully installed munch-2.5.0\n"
          ]
        }
      ],
      "source": [
        "!pip install munch==2.5.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 512
        },
        "id": "4zxNgnAr814m",
        "outputId": "59052189-7814-4a79-e401-c8cca00c87c0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting numpy==1.21.6\n",
            "  Downloading numpy-1.21.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (15.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.9/15.9 MB\u001b[0m \u001b[31m70.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: numpy\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.25.2\n",
            "    Uninstalling numpy-1.25.2:\n",
            "      Successfully uninstalled numpy-1.25.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "chex 0.1.86 requires numpy>=1.24.1, but you have numpy 1.21.6 which is incompatible.\n",
            "cudf-cu12 24.4.1 requires numpy<2.0a0,>=1.23, but you have numpy 1.21.6 which is incompatible.\n",
            "flax 0.8.3 requires numpy>=1.22, but you have numpy 1.21.6 which is incompatible.\n",
            "jax 0.4.26 requires numpy>=1.22, but you have numpy 1.21.6 which is incompatible.\n",
            "jaxlib 0.4.26+cuda12.cudnn89 requires numpy>=1.22, but you have numpy 1.21.6 which is incompatible.\n",
            "numba 0.58.1 requires numpy<1.27,>=1.22, but you have numpy 1.21.6 which is incompatible.\n",
            "pandas-stubs 2.0.3.230814 requires numpy>=1.25.0; python_version >= \"3.9\", but you have numpy 1.21.6 which is incompatible.\n",
            "plotnine 0.12.4 requires numpy>=1.23.0, but you have numpy 1.21.6 which is incompatible.\n",
            "pywavelets 1.6.0 requires numpy<3,>=1.22.4, but you have numpy 1.21.6 which is incompatible.\n",
            "rmm-cu12 24.4.0 requires numpy<2.0a0,>=1.23, but you have numpy 1.21.6 which is incompatible.\n",
            "statsmodels 0.14.2 requires numpy>=1.22.3, but you have numpy 1.21.6 which is incompatible.\n",
            "tensorflow 2.15.0 requires numpy<2.0.0,>=1.23.5, but you have numpy 1.21.6 which is incompatible.\n",
            "xarray-einstats 0.7.0 requires numpy>=1.22, but you have numpy 1.21.6 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed numpy-1.21.6\n"
          ]
        },
        {
          "data": {
            "application/vnd.colab-display-data+json": {
              "id": "aae030cbd1ca4a1d8d55f1abf17e0f8c",
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "!pip install numpy==1.21.6"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "djGc047q7KHJ"
      },
      "outputs": [],
      "source": [
        "!rm -rf UFold/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VIl8wcrM8eyo",
        "outputId": "57bd220e-f1b9-4208-e7fa-1d5ad1017d94"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "#####Stage 1#####\n",
            "Here is the configuration of this run: \n",
            "Munch({'gpu': '1', 'u_net_d': 2, 'BATCH_SIZE': 1, 'batch_size_stage_1': 1, 'OUT_STEP': 10, 'LOAD_MODEL': True, 'rho_per_position': 'matrix', 'data_type': 'rnastralign_all_600', 'model_type': 'pretrained', 'epoches_first': 10, 'step_gamma': 1, 'k': 1})\n",
            "Loading dataset:  ArchiveII_train\n",
            "/content/UFold/ufold/data_generator.py:44: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  self.pairs = np.array([instance[-1] for instance in self.data])\n",
            "Loading dataset:  ArchiveII_valid\n",
            "Data Loading Done!!!\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "start training...\n",
            "  0% 0/10 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:512: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3587.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:512: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3587.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:512: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3587.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:512: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3587.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            "0 done in batch.\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:512: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3587.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:512: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3587.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            "100 done in batch.\n",
            "200 done in batch.\n",
            "300 done in batch.\n",
            "Training log: epoch: 0, step: 394, loss: 0.3569338619709015\n",
            " 10% 1/10 [14:53<2:13:59, 893.33s/it]/usr/local/lib/python3.10/dist-packages/torch/functional.py:512: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3587.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:512: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3587.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:512: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3587.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            "0 done in batch.\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:512: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3587.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:512: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3587.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:512: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3587.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            "100 done in batch.\n",
            "200 done in batch.\n",
            "300 done in batch.\n",
            "Training log: epoch: 1, step: 789, loss: 0.38495469093322754\n",
            " 20% 2/10 [29:34<1:58:09, 886.19s/it]/usr/local/lib/python3.10/dist-packages/torch/functional.py:512: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3587.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:512: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3587.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:512: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3587.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:512: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3587.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            "0 done in batch.\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:512: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3587.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:512: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3587.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            "100 done in batch.\n",
            "^C\n"
          ]
        }
      ],
      "source": [
        "!cd UFold/ && \\\n",
        "python ufold_train.py \\\n",
        "--train_files ArchiveII_train ArchiveII_valid \\\n",
        "--model_pt ArchiveII_unet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M4jp5-9C-0Sk",
        "outputId": "471a69aa-d4db-4203-ea25-4bedcb7268d7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "#####Stage 1#####\n",
            "Here is the configuration of this run: \n",
            "Munch({'gpu': '1', 'u_net_d': 2, 'BATCH_SIZE': 1, 'batch_size_stage_1': 1, 'OUT_STEP': 10, 'LOAD_MODEL': True, 'rho_per_position': 'matrix', 'data_type': 'rnastralign_all_600', 'model_type': 'pretrained', 'epoches_first': 10, 'step_gamma': 1, 'k': 1})\n",
            "Loading dataset:  PDB_train\n",
            "/content/UFold/ufold/data_generator.py:43: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  self.pairs = np.array([instance[-1] for instance in self.data])\n",
            "Loading dataset:  PDB_valid\n",
            "Data Loading Done!!!\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "start training...\n",
            "  0% 0/10 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "0 done in batch.\n",
            "100 done in batch.\n",
            "200 done in batch.\n",
            "300 done in batch.\n",
            "400 done in batch.\n",
            "500 done in batch.\n",
            "Training log: epoch: 0, step: 539, loss: 0.6381824612617493\n",
            " 10% 1/10 [05:13<46:58, 313.17s/it]0 done in batch.\n",
            "100 done in batch.\n",
            "200 done in batch.\n",
            "300 done in batch.\n",
            "400 done in batch.\n",
            "500 done in batch.\n",
            "Training log: epoch: 1, step: 1079, loss: 0.48643362522125244\n",
            " 20% 2/10 [10:13<40:47, 305.90s/it]0 done in batch.\n",
            "100 done in batch.\n",
            "200 done in batch.\n",
            "300 done in batch.\n",
            "400 done in batch.\n",
            "500 done in batch.\n",
            "Training log: epoch: 2, step: 1619, loss: 0.661521315574646\n",
            " 30% 3/10 [15:13<35:19, 302.81s/it]0 done in batch.\n",
            "100 done in batch.\n",
            "200 done in batch.\n",
            "300 done in batch.\n",
            "400 done in batch.\n",
            "500 done in batch.\n",
            "Training log: epoch: 3, step: 2159, loss: 0.3293929696083069\n",
            " 40% 4/10 [20:13<30:10, 301.76s/it]0 done in batch.\n",
            "100 done in batch.\n",
            "200 done in batch.\n",
            "300 done in batch.\n",
            "400 done in batch.\n",
            "500 done in batch.\n",
            "Training log: epoch: 4, step: 2699, loss: 0.3745020925998688\n",
            " 50% 5/10 [25:10<25:01, 300.22s/it]0 done in batch.\n",
            "100 done in batch.\n",
            "200 done in batch.\n",
            "300 done in batch.\n",
            "400 done in batch.\n",
            "500 done in batch.\n",
            "Training log: epoch: 5, step: 3239, loss: 0.30505457520484924\n",
            " 60% 6/10 [30:12<20:03, 300.86s/it]0 done in batch.\n",
            "100 done in batch.\n",
            "200 done in batch.\n",
            "300 done in batch.\n",
            "400 done in batch.\n",
            "500 done in batch.\n",
            "Training log: epoch: 6, step: 3779, loss: 0.37650352716445923\n",
            " 70% 7/10 [35:13<15:02, 300.81s/it]0 done in batch.\n",
            "100 done in batch.\n",
            "200 done in batch.\n",
            "300 done in batch.\n",
            "400 done in batch.\n",
            "500 done in batch.\n",
            "Training log: epoch: 7, step: 4319, loss: 0.6182111501693726\n",
            " 80% 8/10 [40:13<10:00, 300.50s/it]0 done in batch.\n",
            "100 done in batch.\n",
            "200 done in batch.\n",
            "300 done in batch.\n",
            "400 done in batch.\n",
            "500 done in batch.\n",
            "Training log: epoch: 8, step: 4859, loss: 0.24195927381515503\n",
            " 90% 9/10 [45:08<04:58, 298.79s/it]0 done in batch.\n",
            "100 done in batch.\n",
            "200 done in batch.\n",
            "300 done in batch.\n",
            "400 done in batch.\n",
            "500 done in batch.\n",
            "Training log: epoch: 9, step: 5399, loss: 0.3240619897842407\n",
            "100% 10/10 [50:07<00:00, 300.72s/it]\n"
          ]
        }
      ],
      "source": [
        "!cd UFold/ && \\\n",
        "python ufold_train.py \\\n",
        "--train_files PDB_train PDB_valid \\\n",
        "--model_pt PDB_unet"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cd UFold/ && \\\n",
        "python ufold_test.py --test_files ArchiveII_test \\\n",
        "--model_pt ../ArchiveII_unet_1.pt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J0nUr9yY-f2d",
        "outputId": "9c582358-c345-4fd6-d622-8509ba106995"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading test file:  ArchiveII_test\n",
            "/content/UFold/ufold/data_generator.py:44: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  self.pairs = np.array([instance[-1] for instance in self.data])\n",
            "Max seq length  600\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "==========Start Loading==========\n",
            "==========Finish Loading==========\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:512: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3587.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:512: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3587.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:512: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3587.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:512: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3587.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:512: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3587.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:512: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3587.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            "Batch number:  0\n",
            "tensor(172.) tensor(92244.)\n",
            "tensor(206.) tensor(123698.)\n",
            "tensor(202.) tensor(92214.)\n",
            "tensor(146.) tensor(65390.)\n",
            "tensor(50.) tensor(9166.)\n",
            "tensor(70.) tensor(16314.)\n",
            "tensor(78.) tensor(16306.)\n",
            "tensor(70.) tensor(16314.)\n",
            "tensor(66.) tensor(16318.)\n",
            "tensor(58.) tensor(12486.)\n",
            "tensor(60.) tensor(12484.)\n",
            "tensor(76.) tensor(16308.)\n",
            "tensor(240.) tensor(172816.)\n",
            "tensor(118.) tensor(135306.)\n",
            "tensor(72.) tensor(16312.)\n",
            "tensor(40.) tensor(6360.)\n",
            "tensor(66.) tensor(16318.)\n",
            "tensor(42.) tensor(9174.)\n",
            "tensor(204.) tensor(135220.)\n",
            "tensor(196.) tensor(123708.)\n",
            "tensor(160.) tensor(92256.)\n",
            "tensor(14.) tensor(6386.)\n",
            "tensor(66.) tensor(12478.)\n",
            "tensor(172.) tensor(112724.)\n",
            "tensor(184.) tensor(135240.)\n",
            "tensor(70.) tensor(16314.)\n",
            "tensor(68.) tensor(16316.)\n",
            "tensor(140.) tensor(313460.)\n",
            "tensor(256.) tensor(159744.)\n",
            "tensor(238.) tensor(172818.)\n",
            "tensor(128.) tensor(102272.)\n",
            "tensor(134.) tensor(82810.)\n",
            "tensor(42.) tensor(6358.)\n",
            "tensor(72.) tensor(16312.)\n",
            "tensor(68.) tensor(16316.)\n",
            "tensor(204.) tensor(147252.)\n",
            "tensor(142.) tensor(65394.)\n",
            "tensor(42.) tensor(9174.)\n",
            "tensor(66.) tensor(12478.)\n",
            "tensor(122.) tensor(82822.)\n",
            "tensor(14.) tensor(16370.)\n",
            "tensor(154.) tensor(73830.)\n",
            "tensor(42.) tensor(6358.)\n",
            "tensor(212.) tensor(159788.)\n",
            "tensor(70.) tensor(16314.)\n",
            "tensor(40.) tensor(6360.)\n",
            "tensor(124.) tensor(57476.)\n",
            "tensor(122.) tensor(82822.)\n",
            "tensor(204.) tensor(92212.)\n",
            "tensor(42.) tensor(6358.)\n",
            "tensor(70.) tensor(16314.)\n",
            "tensor(170.) tensor(92246.)\n",
            "tensor(72.) tensor(16312.)\n",
            "tensor(118.) tensor(57482.)\n",
            "tensor(72.) tensor(16312.)\n",
            "tensor(120.) tensor(172936.)\n",
            "tensor(52.) tensor(12492.)\n",
            "tensor(70.) tensor(16314.)\n",
            "tensor(42.) tensor(6358.)\n",
            "tensor(60.) tensor(16324.)\n",
            "tensor(46.) tensor(9170.)\n",
            "tensor(68.) tensor(16316.)\n",
            "tensor(72.) tensor(16312.)\n",
            "tensor(66.) tensor(16318.)\n",
            "tensor(84.) tensor(20652.)\n",
            "tensor(70.) tensor(16314.)\n",
            "tensor(120.) tensor(50056.)\n",
            "tensor(70.) tensor(16314.)\n",
            "tensor(68.) tensor(16316.)\n",
            "tensor(42.) tensor(6358.)\n",
            "tensor(62.) tensor(16322.)\n",
            "tensor(64.) tensor(16320.)\n",
            "tensor(208.) tensor(147248.)\n",
            "tensor(42.) tensor(6358.)\n",
            "tensor(62.) tensor(12482.)\n",
            "tensor(72.) tensor(16312.)\n",
            "Average testing F1 score with pure post-processing:  0.43426058\n",
            "Average testing precision with pure post-processing:  0.4694383\n",
            "Average testing recall with pure post-processing:  0.42284623\n",
            "Average testing specificity with pure post-processing:  0.9984806\n",
            "Average testing g-mean with pure post-processing:  0.61080265\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cd UFold/ && \\\n",
        "python ufold_test.py --test_files PDB_test \\\n",
        "--model_pt ../PDB_unet_9.pt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u0IZp8N0_Ydz",
        "outputId": "1c933d93-43a5-40da-cc76-6ff9e470b583"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading test file:  PDB_test\n",
            "/content/UFold/ufold/data_generator.py:44: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  self.pairs = np.array([instance[-1] for instance in self.data])\n",
            "Max seq length  600\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "==========Start Loading==========\n",
            "==========Finish Loading==========\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:512: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3587.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:512: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3587.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:512: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3587.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:512: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3587.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:512: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3587.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:512: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3587.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            "Batch number:  0\n",
            "tensor(56.) tensor(9160.)\n",
            "tensor(50.) tensor(9166.)\n",
            "tensor(90.) tensor(25510.)\n",
            "tensor(98.) tensor(25502.)\n",
            "tensor(42.) tensor(6358.)\n",
            "tensor(30.) tensor(6370.)\n",
            "tensor(10.) tensor(6390.)\n",
            "tensor(36.) tensor(6364.)\n",
            "tensor(22.) tensor(6378.)\n",
            "tensor(12.) tensor(6388.)\n",
            "tensor(12.) tensor(6388.)\n",
            "tensor(52.) tensor(9164.)\n",
            "tensor(10.) tensor(6390.)\n",
            "tensor(12.) tensor(6388.)\n",
            "tensor(10.) tensor(6390.)\n",
            "tensor(12.) tensor(6388.)\n",
            "tensor(8.) tensor(6392.)\n",
            "tensor(12.) tensor(6388.)\n",
            "tensor(24.) tensor(6376.)\n",
            "tensor(8.) tensor(6392.)\n",
            "tensor(20.) tensor(6380.)\n",
            "tensor(38.) tensor(6362.)\n",
            "tensor(44.) tensor(6356.)\n",
            "tensor(72.) tensor(16312.)\n",
            "tensor(66.) tensor(16318.)\n",
            "tensor(42.) tensor(6358.)\n",
            "tensor(10.) tensor(6390.)\n",
            "tensor(54.) tensor(6346.)\n",
            "tensor(52.) tensor(9164.)\n",
            "tensor(12.) tensor(6388.)\n",
            "tensor(16.) tensor(6384.)\n",
            "tensor(40.) tensor(6360.)\n",
            "tensor(58.) tensor(9158.)\n",
            "tensor(70.) tensor(16314.)\n",
            "tensor(12.) tensor(6388.)\n",
            "tensor(26.) tensor(6374.)\n",
            "tensor(26.) tensor(6374.)\n",
            "tensor(38.) tensor(6362.)\n",
            "tensor(96.) tensor(36768.)\n",
            "tensor(50.) tensor(6350.)\n",
            "tensor(40.) tensor(6360.)\n",
            "tensor(56.) tensor(12488.)\n",
            "tensor(10.) tensor(6390.)\n",
            "tensor(42.) tensor(6358.)\n",
            "tensor(10.) tensor(6390.)\n",
            "tensor(12.) tensor(6388.)\n",
            "tensor(38.) tensor(6362.)\n",
            "tensor(36.) tensor(6364.)\n",
            "tensor(64.) tensor(16320.)\n",
            "tensor(36.) tensor(6364.)\n",
            "tensor(8.) tensor(6392.)\n",
            "tensor(14.) tensor(6386.)\n",
            "tensor(10.) tensor(6390.)\n",
            "tensor(46.) tensor(9170.)\n",
            "tensor(34.) tensor(6366.)\n",
            "tensor(10.) tensor(6390.)\n",
            "tensor(46.) tensor(6354.)\n",
            "tensor(28.) tensor(6372.)\n",
            "tensor(18.) tensor(6382.)\n",
            "tensor(162.) tensor(112734.)\n",
            "tensor(18.) tensor(6382.)\n",
            "tensor(72.) tensor(16312.)\n",
            "tensor(50.) tensor(9166.)\n",
            "tensor(66.) tensor(9150.)\n",
            "tensor(92.) tensor(16292.)\n",
            "tensor(72.) tensor(16312.)\n",
            "tensor(56.) tensor(6344.)\n",
            "tensor(8.) tensor(6392.)\n",
            "tensor(44.) tensor(6356.)\n",
            "tensor(50.) tensor(6350.)\n",
            "tensor(2.) tensor(6398.)\n",
            "tensor(30.) tensor(6370.)\n",
            "tensor(34.) tensor(6366.)\n",
            "tensor(12.) tensor(6388.)\n",
            "tensor(82.) tensor(16302.)\n",
            "tensor(12.) tensor(6388.)\n",
            "tensor(46.) tensor(6354.)\n",
            "tensor(24.) tensor(6376.)\n",
            "tensor(8.) tensor(6392.)\n",
            "tensor(24.) tensor(6376.)\n",
            "tensor(40.) tensor(6360.)\n",
            "tensor(44.) tensor(9172.)\n",
            "tensor(40.) tensor(9176.)\n",
            "tensor(32.) tensor(16352.)\n",
            "tensor(46.) tensor(6354.)\n",
            "tensor(10.) tensor(6390.)\n",
            "tensor(48.) tensor(6352.)\n",
            "tensor(50.) tensor(9166.)\n",
            "tensor(16.) tensor(6384.)\n",
            "tensor(28.) tensor(6372.)\n",
            "tensor(4.) tensor(6396.)\n",
            "tensor(32.) tensor(6368.)\n",
            "tensor(46.) tensor(6354.)\n",
            "tensor(6.) tensor(6394.)\n",
            "tensor(8.) tensor(6392.)\n",
            "tensor(24.) tensor(6376.)\n",
            "tensor(42.) tensor(6358.)\n",
            "tensor(32.) tensor(6368.)\n",
            "tensor(10.) tensor(6390.)\n",
            "tensor(28.) tensor(6372.)\n",
            "tensor(36.) tensor(6364.)\n",
            "tensor(48.) tensor(9168.)\n",
            "tensor(48.) tensor(6352.)\n",
            "tensor(44.) tensor(6356.)\n",
            "tensor(12.) tensor(6388.)\n",
            "tensor(42.) tensor(6358.)\n",
            "tensor(44.) tensor(6356.)\n",
            "tensor(38.) tensor(6362.)\n",
            "tensor(34.) tensor(6366.)\n",
            "tensor(34.) tensor(9182.)\n",
            "tensor(20.) tensor(6380.)\n",
            "Average testing F1 score with pure post-processing:  0.68099666\n",
            "Average testing precision with pure post-processing:  0.6493637\n",
            "Average testing recall with pure post-processing:  0.7350563\n",
            "Average testing specificity with pure post-processing:  0.9984547\n",
            "Average testing g-mean with pure post-processing:  0.8227881\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MhDp0WTkBfCF"
      },
      "source": [
        "## Transfer learning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JdMzdRfnAHP1",
        "outputId": "9cdae0d2-088d-41ba-f4c2-3344fdc6f55e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "#####Stage 1#####\n",
            "Here is the configuration of this run: \n",
            "Munch({'gpu': '1', 'u_net_d': 2, 'BATCH_SIZE': 1, 'batch_size_stage_1': 1, 'OUT_STEP': 10, 'LOAD_MODEL': True, 'rho_per_position': 'matrix', 'data_type': 'rnastralign_all_600', 'model_type': 'pretrained', 'epoches_first': 10, 'step_gamma': 1, 'k': 1})\n",
            "Loading dataset:  PDB_train\n",
            "/content/UFold/ufold/data_generator.py:43: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  self.pairs = np.array([instance[-1] for instance in self.data])\n",
            "Loading dataset:  PDB_valid\n",
            "Data Loading Done!!!\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "Loading u net model...\n",
            "start training...\n",
            "  0% 0/10 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "0 done in batch.\n",
            "100 done in batch.\n",
            "200 done in batch.\n",
            "300 done in batch.\n",
            "400 done in batch.\n",
            "500 done in batch.\n",
            "Training log: epoch: 0, step: 539, loss: 0.5867913961410522\n",
            " 10% 1/10 [05:00<45:07, 300.88s/it]0 done in batch.\n",
            "100 done in batch.\n",
            "200 done in batch.\n",
            "300 done in batch.\n",
            "400 done in batch.\n",
            "500 done in batch.\n",
            "Training log: epoch: 1, step: 1079, loss: 0.3535248637199402\n",
            " 20% 2/10 [09:56<39:40, 297.51s/it]0 done in batch.\n",
            "100 done in batch.\n",
            "200 done in batch.\n",
            "300 done in batch.\n",
            "400 done in batch.\n",
            "500 done in batch.\n",
            "Training log: epoch: 2, step: 1619, loss: 0.65691077709198\n",
            " 30% 3/10 [14:54<34:46, 298.13s/it]0 done in batch.\n",
            "100 done in batch.\n",
            "200 done in batch.\n",
            "300 done in batch.\n",
            "400 done in batch.\n",
            "500 done in batch.\n",
            "Training log: epoch: 3, step: 2159, loss: 0.24321721494197845\n",
            " 40% 4/10 [20:04<30:16, 302.79s/it]0 done in batch.\n",
            "100 done in batch.\n",
            "200 done in batch.\n",
            "300 done in batch.\n",
            "400 done in batch.\n",
            "500 done in batch.\n",
            "Training log: epoch: 4, step: 2699, loss: 0.3824821710586548\n",
            " 50% 5/10 [25:20<25:37, 307.50s/it]0 done in batch.\n",
            "100 done in batch.\n",
            "200 done in batch.\n",
            "300 done in batch.\n",
            "400 done in batch.\n",
            "500 done in batch.\n",
            "Training log: epoch: 5, step: 3239, loss: 0.2584899663925171\n",
            " 60% 6/10 [30:16<20:14, 303.61s/it]0 done in batch.\n",
            "100 done in batch.\n",
            "200 done in batch.\n",
            "300 done in batch.\n",
            "400 done in batch.\n",
            "500 done in batch.\n",
            "Training log: epoch: 6, step: 3779, loss: 0.3902072608470917\n",
            " 70% 7/10 [35:13<15:04, 301.52s/it]0 done in batch.\n",
            "100 done in batch.\n",
            "200 done in batch.\n",
            "300 done in batch.\n",
            "400 done in batch.\n",
            "500 done in batch.\n",
            "Training log: epoch: 7, step: 4319, loss: 0.6120731830596924\n",
            " 80% 8/10 [40:12<10:00, 300.47s/it]0 done in batch.\n",
            "100 done in batch.\n",
            "200 done in batch.\n",
            "300 done in batch.\n",
            "400 done in batch.\n",
            "500 done in batch.\n",
            "Training log: epoch: 8, step: 4859, loss: 0.23431289196014404\n",
            " 90% 9/10 [45:06<04:58, 298.52s/it]0 done in batch.\n",
            "100 done in batch.\n",
            "200 done in batch.\n",
            "300 done in batch.\n",
            "400 done in batch.\n",
            "500 done in batch.\n",
            "Training log: epoch: 9, step: 5399, loss: 0.3588309586048126\n",
            "100% 10/10 [50:08<00:00, 300.81s/it]\n"
          ]
        }
      ],
      "source": [
        "!cd UFold/ && \\\n",
        "python ufold_train.py \\\n",
        "--train_files PDB_train PDB_valid \\\n",
        "--model_pt ArchiveII_PDB_unet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XrCPLAGYRui0"
      },
      "source": [
        "### Create transfer learning evaluation files and folders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zDn4IYhcRmEZ"
      },
      "outputs": [],
      "source": [
        "!mkdir UFold/data/joined\n",
        "!mkdir UFold/data/joined/test\n",
        "!cp UFold/data/ArchiveII_bpseq/test/* UFold/data/joined/test\n",
        "!cp UFold/data/PDB_bpseq/test/* UFold/data/joined/test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jEBO5P1_SW7u",
        "outputId": "b03b658f-c0cf-4ed4-cb96-e7c764e63694"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "current processing 1/198\n",
            "187\n"
          ]
        }
      ],
      "source": [
        "!cd UFold && python process_data_newdataset.py data/joined/test data/joined_test.cPickle"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cd UFold/ && \\\n",
        "python ufold_test.py --test_files joined_test \\\n",
        "--model_pt ../ArchiveII_PDB_unet_9.pt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tJqtHFFDsz4D",
        "outputId": "f5e40119-fa34-4dab-cda7-95d69fe7cb4c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading test file:  joined_test\n",
            "/content/UFold/ufold/data_generator.py:44: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  self.pairs = np.array([instance[-1] for instance in self.data])\n",
            "Max seq length  600\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "==========Start Loading==========\n",
            "==========Finish Loading==========\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:512: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3587.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:512: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3587.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:512: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3587.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:512: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3587.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:512: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3587.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:512: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3587.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            "Batch number:  0\n",
            "tensor(208.) tensor(147248.)\n",
            "tensor(162.) tensor(112734.)\n",
            "tensor(170.) tensor(92246.)\n",
            "tensor(72.) tensor(16312.)\n",
            "tensor(72.) tensor(16312.)\n",
            "tensor(62.) tensor(16322.)\n",
            "tensor(70.) tensor(16314.)\n",
            "tensor(46.) tensor(9170.)\n",
            "tensor(42.) tensor(6358.)\n",
            "tensor(42.) tensor(6358.)\n",
            "tensor(8.) tensor(6392.)\n",
            "tensor(38.) tensor(6362.)\n",
            "tensor(14.) tensor(6386.)\n",
            "tensor(36.) tensor(6364.)\n",
            "tensor(50.) tensor(6350.)\n",
            "tensor(38.) tensor(6362.)\n",
            "tensor(12.) tensor(6388.)\n",
            "tensor(72.) tensor(16312.)\n",
            "tensor(20.) tensor(6380.)\n",
            "tensor(38.) tensor(6362.)\n",
            "tensor(70.) tensor(16314.)\n",
            "tensor(10.) tensor(6390.)\n",
            "tensor(48.) tensor(9168.)\n",
            "tensor(146.) tensor(65390.)\n",
            "tensor(56.) tensor(6344.)\n",
            "tensor(66.) tensor(16318.)\n",
            "tensor(40.) tensor(6360.)\n",
            "tensor(28.) tensor(6372.)\n",
            "tensor(72.) tensor(16312.)\n",
            "tensor(56.) tensor(12488.)\n",
            "tensor(70.) tensor(16314.)\n",
            "tensor(92.) tensor(16292.)\n",
            "tensor(40.) tensor(9176.)\n",
            "tensor(46.) tensor(6354.)\n",
            "tensor(44.) tensor(6356.)\n",
            "tensor(44.) tensor(6356.)\n",
            "tensor(8.) tensor(6392.)\n",
            "tensor(12.) tensor(6388.)\n",
            "tensor(40.) tensor(6360.)\n",
            "tensor(42.) tensor(6358.)\n",
            "tensor(50.) tensor(9166.)\n",
            "tensor(70.) tensor(16314.)\n",
            "tensor(172.) tensor(112724.)\n",
            "tensor(70.) tensor(16314.)\n",
            "tensor(160.) tensor(92256.)\n",
            "tensor(238.) tensor(172818.)\n",
            "tensor(32.) tensor(6368.)\n",
            "tensor(50.) tensor(9166.)\n",
            "tensor(26.) tensor(6374.)\n",
            "tensor(44.) tensor(6356.)\n",
            "tensor(26.) tensor(6374.)\n",
            "tensor(68.) tensor(16316.)\n",
            "tensor(60.) tensor(12484.)\n",
            "tensor(68.) tensor(16316.)\n",
            "tensor(10.) tensor(6390.)\n",
            "tensor(42.) tensor(9174.)\n",
            "tensor(52.) tensor(12492.)\n",
            "tensor(140.) tensor(313460.)\n",
            "tensor(48.) tensor(6352.)\n",
            "tensor(28.) tensor(6372.)\n",
            "tensor(8.) tensor(6392.)\n",
            "tensor(98.) tensor(25502.)\n",
            "tensor(46.) tensor(6354.)\n",
            "tensor(72.) tensor(16312.)\n",
            "tensor(16.) tensor(6384.)\n",
            "tensor(68.) tensor(16316.)\n",
            "tensor(122.) tensor(82822.)\n",
            "tensor(24.) tensor(6376.)\n",
            "tensor(12.) tensor(6388.)\n",
            "tensor(172.) tensor(92244.)\n",
            "tensor(212.) tensor(159788.)\n",
            "tensor(40.) tensor(6360.)\n",
            "tensor(40.) tensor(6360.)\n",
            "tensor(38.) tensor(6362.)\n",
            "tensor(54.) tensor(6346.)\n",
            "tensor(10.) tensor(6390.)\n",
            "tensor(46.) tensor(9170.)\n",
            "tensor(70.) tensor(16314.)\n",
            "tensor(122.) tensor(82822.)\n",
            "tensor(34.) tensor(6366.)\n",
            "tensor(58.) tensor(12486.)\n",
            "tensor(134.) tensor(82810.)\n",
            "tensor(240.) tensor(172816.)\n",
            "tensor(36.) tensor(6364.)\n",
            "tensor(20.) tensor(6380.)\n",
            "tensor(12.) tensor(6388.)\n",
            "tensor(82.) tensor(16302.)\n",
            "tensor(12.) tensor(6388.)\n",
            "tensor(184.) tensor(135240.)\n",
            "tensor(58.) tensor(9158.)\n",
            "tensor(66.) tensor(16318.)\n",
            "tensor(42.) tensor(6358.)\n",
            "tensor(42.) tensor(6358.)\n",
            "tensor(10.) tensor(6390.)\n",
            "tensor(42.) tensor(6358.)\n",
            "tensor(44.) tensor(6356.)\n",
            "tensor(10.) tensor(6390.)\n",
            "tensor(72.) tensor(16312.)\n",
            "tensor(70.) tensor(16314.)\n",
            "tensor(90.) tensor(25510.)\n",
            "tensor(48.) tensor(6352.)\n",
            "tensor(18.) tensor(6382.)\n",
            "tensor(10.) tensor(6390.)\n",
            "tensor(30.) tensor(6370.)\n",
            "tensor(128.) tensor(102272.)\n",
            "tensor(56.) tensor(9160.)\n",
            "tensor(66.) tensor(12478.)\n",
            "tensor(42.) tensor(6358.)\n",
            "tensor(4.) tensor(6396.)\n",
            "tensor(18.) tensor(6382.)\n",
            "tensor(78.) tensor(16306.)\n",
            "tensor(16.) tensor(6384.)\n",
            "tensor(8.) tensor(6392.)\n",
            "tensor(24.) tensor(6376.)\n",
            "tensor(204.) tensor(135220.)\n",
            "tensor(196.) tensor(123708.)\n",
            "tensor(32.) tensor(6368.)\n",
            "tensor(8.) tensor(6392.)\n",
            "tensor(50.) tensor(9166.)\n",
            "tensor(46.) tensor(6354.)\n",
            "tensor(42.) tensor(6358.)\n",
            "tensor(204.) tensor(92212.)\n",
            "tensor(12.) tensor(6388.)\n",
            "tensor(22.) tensor(6378.)\n",
            "tensor(46.) tensor(6354.)\n",
            "tensor(70.) tensor(16314.)\n",
            "tensor(12.) tensor(6388.)\n",
            "tensor(30.) tensor(6370.)\n",
            "tensor(118.) tensor(57482.)\n",
            "tensor(12.) tensor(6388.)\n",
            "tensor(256.) tensor(159744.)\n",
            "tensor(124.) tensor(57476.)\n",
            "tensor(10.) tensor(6390.)\n",
            "tensor(36.) tensor(6364.)\n",
            "tensor(52.) tensor(9164.)\n",
            "tensor(42.) tensor(6358.)\n",
            "tensor(34.) tensor(6366.)\n",
            "tensor(72.) tensor(16312.)\n",
            "tensor(118.) tensor(135306.)\n",
            "tensor(72.) tensor(16312.)\n",
            "tensor(8.) tensor(6392.)\n",
            "tensor(202.) tensor(92214.)\n",
            "tensor(68.) tensor(16316.)\n",
            "tensor(34.) tensor(6366.)\n",
            "tensor(66.) tensor(12478.)\n",
            "tensor(96.) tensor(36768.)\n",
            "tensor(64.) tensor(16320.)\n",
            "tensor(50.) tensor(9166.)\n",
            "tensor(70.) tensor(16314.)\n",
            "tensor(28.) tensor(6372.)\n",
            "tensor(52.) tensor(9164.)\n",
            "tensor(32.) tensor(16352.)\n",
            "tensor(24.) tensor(6376.)\n",
            "tensor(34.) tensor(9182.)\n",
            "tensor(120.) tensor(172936.)\n",
            "tensor(60.) tensor(16324.)\n",
            "tensor(6.) tensor(6394.)\n",
            "tensor(120.) tensor(50056.)\n",
            "tensor(12.) tensor(6388.)\n",
            "tensor(2.) tensor(6398.)\n",
            "tensor(12.) tensor(6388.)\n",
            "tensor(42.) tensor(6358.)\n",
            "tensor(24.) tensor(6376.)\n",
            "tensor(50.) tensor(6350.)\n",
            "tensor(206.) tensor(123698.)\n",
            "tensor(42.) tensor(6358.)\n",
            "tensor(142.) tensor(65394.)\n",
            "tensor(62.) tensor(12482.)\n",
            "tensor(10.) tensor(6390.)\n",
            "tensor(76.) tensor(16308.)\n",
            "tensor(14.) tensor(6386.)\n",
            "tensor(42.) tensor(9174.)\n",
            "tensor(66.) tensor(16318.)\n",
            "tensor(36.) tensor(6364.)\n",
            "tensor(66.) tensor(9150.)\n",
            "tensor(204.) tensor(147252.)\n",
            "tensor(72.) tensor(16312.)\n",
            "tensor(10.) tensor(6390.)\n",
            "tensor(44.) tensor(9172.)\n",
            "tensor(10.) tensor(6390.)\n",
            "tensor(84.) tensor(20652.)\n",
            "tensor(154.) tensor(73830.)\n",
            "tensor(40.) tensor(6360.)\n",
            "tensor(64.) tensor(16320.)\n",
            "tensor(12.) tensor(6388.)\n",
            "tensor(14.) tensor(16370.)\n",
            "tensor(66.) tensor(16318.)\n",
            "Average testing F1 score with pure post-processing:  0.5899272\n",
            "Average testing precision with pure post-processing:  0.5619337\n",
            "Average testing recall with pure post-processing:  0.6375114\n",
            "Average testing specificity with pure post-processing:  0.9982655\n",
            "Average testing g-mean with pure post-processing:  0.76088697\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cd UFold/ && \\\n",
        "python ufold_test.py --test_files ArchiveII_test \\\n",
        "--model_pt ../ArchiveII_PDB_unet_9.pt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VV28dV7i9Jcs",
        "outputId": "1eac4d80-09a5-4c6b-af8d-488b60aab20d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading test file:  ArchiveII_test\n",
            "/content/UFold/ufold/data_generator.py:44: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  self.pairs = np.array([instance[-1] for instance in self.data])\n",
            "Max seq length  600\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "==========Start Loading==========\n",
            "==========Finish Loading==========\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:512: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3587.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:512: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3587.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:512: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3587.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:512: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3587.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:512: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3587.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:512: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3587.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            "Batch number:  0\n",
            "tensor(172.) tensor(92244.)\n",
            "tensor(206.) tensor(123698.)\n",
            "tensor(202.) tensor(92214.)\n",
            "tensor(146.) tensor(65390.)\n",
            "tensor(50.) tensor(9166.)\n",
            "tensor(70.) tensor(16314.)\n",
            "tensor(78.) tensor(16306.)\n",
            "tensor(70.) tensor(16314.)\n",
            "tensor(66.) tensor(16318.)\n",
            "tensor(58.) tensor(12486.)\n",
            "tensor(60.) tensor(12484.)\n",
            "tensor(76.) tensor(16308.)\n",
            "tensor(240.) tensor(172816.)\n",
            "tensor(118.) tensor(135306.)\n",
            "tensor(72.) tensor(16312.)\n",
            "tensor(40.) tensor(6360.)\n",
            "tensor(66.) tensor(16318.)\n",
            "tensor(42.) tensor(9174.)\n",
            "tensor(204.) tensor(135220.)\n",
            "tensor(196.) tensor(123708.)\n",
            "tensor(160.) tensor(92256.)\n",
            "tensor(14.) tensor(6386.)\n",
            "tensor(66.) tensor(12478.)\n",
            "tensor(172.) tensor(112724.)\n",
            "tensor(184.) tensor(135240.)\n",
            "tensor(70.) tensor(16314.)\n",
            "tensor(68.) tensor(16316.)\n",
            "tensor(140.) tensor(313460.)\n",
            "tensor(256.) tensor(159744.)\n",
            "tensor(238.) tensor(172818.)\n",
            "tensor(128.) tensor(102272.)\n",
            "tensor(134.) tensor(82810.)\n",
            "tensor(42.) tensor(6358.)\n",
            "tensor(72.) tensor(16312.)\n",
            "tensor(68.) tensor(16316.)\n",
            "tensor(204.) tensor(147252.)\n",
            "tensor(142.) tensor(65394.)\n",
            "tensor(42.) tensor(9174.)\n",
            "tensor(66.) tensor(12478.)\n",
            "tensor(122.) tensor(82822.)\n",
            "tensor(14.) tensor(16370.)\n",
            "tensor(154.) tensor(73830.)\n",
            "tensor(42.) tensor(6358.)\n",
            "tensor(212.) tensor(159788.)\n",
            "tensor(70.) tensor(16314.)\n",
            "tensor(40.) tensor(6360.)\n",
            "tensor(124.) tensor(57476.)\n",
            "tensor(122.) tensor(82822.)\n",
            "tensor(204.) tensor(92212.)\n",
            "tensor(42.) tensor(6358.)\n",
            "tensor(70.) tensor(16314.)\n",
            "tensor(170.) tensor(92246.)\n",
            "tensor(72.) tensor(16312.)\n",
            "tensor(118.) tensor(57482.)\n",
            "tensor(72.) tensor(16312.)\n",
            "tensor(120.) tensor(172936.)\n",
            "tensor(52.) tensor(12492.)\n",
            "tensor(70.) tensor(16314.)\n",
            "tensor(42.) tensor(6358.)\n",
            "tensor(60.) tensor(16324.)\n",
            "tensor(46.) tensor(9170.)\n",
            "tensor(68.) tensor(16316.)\n",
            "tensor(72.) tensor(16312.)\n",
            "tensor(66.) tensor(16318.)\n",
            "tensor(84.) tensor(20652.)\n",
            "tensor(70.) tensor(16314.)\n",
            "tensor(120.) tensor(50056.)\n",
            "tensor(70.) tensor(16314.)\n",
            "tensor(68.) tensor(16316.)\n",
            "tensor(42.) tensor(6358.)\n",
            "tensor(62.) tensor(16322.)\n",
            "tensor(64.) tensor(16320.)\n",
            "tensor(208.) tensor(147248.)\n",
            "tensor(42.) tensor(6358.)\n",
            "tensor(62.) tensor(12482.)\n",
            "tensor(72.) tensor(16312.)\n",
            "Average testing F1 score with pure post-processing:  0.4725526\n",
            "Average testing precision with pure post-processing:  0.4588808\n",
            "Average testing recall with pure post-processing:  0.49982372\n",
            "Average testing specificity with pure post-processing:  0.99817276\n",
            "Average testing g-mean with pure post-processing:  0.6800407\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cd UFold/ && \\\n",
        "python ufold_test.py --test_files PDB_test \\\n",
        "--model_pt ../ArchiveII_PDB_unet_9.pt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5BDZ3UOK9NtF",
        "outputId": "20b6eb4c-ce9f-4e4f-e327-415d871ed211"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading test file:  PDB_test\n",
            "/content/UFold/ufold/data_generator.py:44: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  self.pairs = np.array([instance[-1] for instance in self.data])\n",
            "Max seq length  600\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "==========Start Loading==========\n",
            "==========Finish Loading==========\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:512: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3587.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:512: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3587.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:512: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3587.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:512: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3587.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:512: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3587.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:512: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3587.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            "Batch number:  0\n",
            "tensor(56.) tensor(9160.)\n",
            "tensor(50.) tensor(9166.)\n",
            "tensor(90.) tensor(25510.)\n",
            "tensor(98.) tensor(25502.)\n",
            "tensor(42.) tensor(6358.)\n",
            "tensor(30.) tensor(6370.)\n",
            "tensor(10.) tensor(6390.)\n",
            "tensor(36.) tensor(6364.)\n",
            "tensor(22.) tensor(6378.)\n",
            "tensor(12.) tensor(6388.)\n",
            "tensor(12.) tensor(6388.)\n",
            "tensor(52.) tensor(9164.)\n",
            "tensor(10.) tensor(6390.)\n",
            "tensor(12.) tensor(6388.)\n",
            "tensor(10.) tensor(6390.)\n",
            "tensor(12.) tensor(6388.)\n",
            "tensor(8.) tensor(6392.)\n",
            "tensor(12.) tensor(6388.)\n",
            "tensor(24.) tensor(6376.)\n",
            "tensor(8.) tensor(6392.)\n",
            "tensor(20.) tensor(6380.)\n",
            "tensor(38.) tensor(6362.)\n",
            "tensor(44.) tensor(6356.)\n",
            "tensor(72.) tensor(16312.)\n",
            "tensor(66.) tensor(16318.)\n",
            "tensor(42.) tensor(6358.)\n",
            "tensor(10.) tensor(6390.)\n",
            "tensor(54.) tensor(6346.)\n",
            "tensor(52.) tensor(9164.)\n",
            "tensor(12.) tensor(6388.)\n",
            "tensor(16.) tensor(6384.)\n",
            "tensor(40.) tensor(6360.)\n",
            "tensor(58.) tensor(9158.)\n",
            "tensor(70.) tensor(16314.)\n",
            "tensor(12.) tensor(6388.)\n",
            "tensor(26.) tensor(6374.)\n",
            "tensor(26.) tensor(6374.)\n",
            "tensor(38.) tensor(6362.)\n",
            "tensor(96.) tensor(36768.)\n",
            "tensor(50.) tensor(6350.)\n",
            "tensor(40.) tensor(6360.)\n",
            "tensor(56.) tensor(12488.)\n",
            "tensor(10.) tensor(6390.)\n",
            "tensor(42.) tensor(6358.)\n",
            "tensor(10.) tensor(6390.)\n",
            "tensor(12.) tensor(6388.)\n",
            "tensor(38.) tensor(6362.)\n",
            "tensor(36.) tensor(6364.)\n",
            "tensor(64.) tensor(16320.)\n",
            "tensor(36.) tensor(6364.)\n",
            "tensor(8.) tensor(6392.)\n",
            "tensor(14.) tensor(6386.)\n",
            "tensor(10.) tensor(6390.)\n",
            "tensor(46.) tensor(9170.)\n",
            "tensor(34.) tensor(6366.)\n",
            "tensor(10.) tensor(6390.)\n",
            "tensor(46.) tensor(6354.)\n",
            "tensor(28.) tensor(6372.)\n",
            "tensor(18.) tensor(6382.)\n",
            "tensor(162.) tensor(112734.)\n",
            "tensor(18.) tensor(6382.)\n",
            "tensor(72.) tensor(16312.)\n",
            "tensor(50.) tensor(9166.)\n",
            "tensor(66.) tensor(9150.)\n",
            "tensor(92.) tensor(16292.)\n",
            "tensor(72.) tensor(16312.)\n",
            "tensor(56.) tensor(6344.)\n",
            "tensor(8.) tensor(6392.)\n",
            "tensor(44.) tensor(6356.)\n",
            "tensor(50.) tensor(6350.)\n",
            "tensor(2.) tensor(6398.)\n",
            "tensor(30.) tensor(6370.)\n",
            "tensor(34.) tensor(6366.)\n",
            "tensor(12.) tensor(6388.)\n",
            "tensor(82.) tensor(16302.)\n",
            "tensor(12.) tensor(6388.)\n",
            "tensor(46.) tensor(6354.)\n",
            "tensor(24.) tensor(6376.)\n",
            "tensor(8.) tensor(6392.)\n",
            "tensor(24.) tensor(6376.)\n",
            "tensor(40.) tensor(6360.)\n",
            "tensor(44.) tensor(9172.)\n",
            "tensor(40.) tensor(9176.)\n",
            "tensor(32.) tensor(16352.)\n",
            "tensor(46.) tensor(6354.)\n",
            "tensor(10.) tensor(6390.)\n",
            "tensor(48.) tensor(6352.)\n",
            "tensor(50.) tensor(9166.)\n",
            "tensor(16.) tensor(6384.)\n",
            "tensor(28.) tensor(6372.)\n",
            "tensor(4.) tensor(6396.)\n",
            "tensor(32.) tensor(6368.)\n",
            "tensor(46.) tensor(6354.)\n",
            "tensor(6.) tensor(6394.)\n",
            "tensor(8.) tensor(6392.)\n",
            "tensor(24.) tensor(6376.)\n",
            "tensor(42.) tensor(6358.)\n",
            "tensor(32.) tensor(6368.)\n",
            "tensor(10.) tensor(6390.)\n",
            "tensor(28.) tensor(6372.)\n",
            "tensor(36.) tensor(6364.)\n",
            "tensor(48.) tensor(9168.)\n",
            "tensor(48.) tensor(6352.)\n",
            "tensor(44.) tensor(6356.)\n",
            "tensor(12.) tensor(6388.)\n",
            "tensor(42.) tensor(6358.)\n",
            "tensor(44.) tensor(6356.)\n",
            "tensor(38.) tensor(6362.)\n",
            "tensor(34.) tensor(6366.)\n",
            "tensor(34.) tensor(9182.)\n",
            "tensor(20.) tensor(6380.)\n",
            "Average testing F1 score with pure post-processing:  0.6702917\n",
            "Average testing precision with pure post-processing:  0.63249236\n",
            "Average testing recall with pure post-processing:  0.73178405\n",
            "Average testing specificity with pure post-processing:  0.99832886\n",
            "Average testing g-mean with pure post-processing:  0.8162408\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cd UFold/ && \\\n",
        "python ufold_test.py --test_files joined_test \\\n",
        "--model_pt ../ArchiveII_unet_1.pt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YFEuxXSss5GC",
        "outputId": "1b6270f2-decc-4e59-d937-be00a47b39dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading test file:  joined_test\n",
            "/content/UFold/ufold/data_generator.py:44: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  self.pairs = np.array([instance[-1] for instance in self.data])\n",
            "Max seq length  600\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "==========Start Loading==========\n",
            "==========Finish Loading==========\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:512: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3587.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:512: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3587.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:512: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3587.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:512: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3587.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:512: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3587.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:512: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3587.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            "Batch number:  0\n",
            "tensor(208.) tensor(147248.)\n",
            "tensor(162.) tensor(112734.)\n",
            "tensor(170.) tensor(92246.)\n",
            "tensor(72.) tensor(16312.)\n",
            "tensor(72.) tensor(16312.)\n",
            "tensor(62.) tensor(16322.)\n",
            "tensor(70.) tensor(16314.)\n",
            "tensor(46.) tensor(9170.)\n",
            "tensor(42.) tensor(6358.)\n",
            "tensor(42.) tensor(6358.)\n",
            "tensor(8.) tensor(6392.)\n",
            "tensor(38.) tensor(6362.)\n",
            "tensor(14.) tensor(6386.)\n",
            "tensor(36.) tensor(6364.)\n",
            "tensor(50.) tensor(6350.)\n",
            "tensor(38.) tensor(6362.)\n",
            "tensor(12.) tensor(6388.)\n",
            "tensor(72.) tensor(16312.)\n",
            "tensor(20.) tensor(6380.)\n",
            "tensor(38.) tensor(6362.)\n",
            "tensor(70.) tensor(16314.)\n",
            "tensor(10.) tensor(6390.)\n",
            "tensor(48.) tensor(9168.)\n",
            "tensor(146.) tensor(65390.)\n",
            "tensor(56.) tensor(6344.)\n",
            "tensor(66.) tensor(16318.)\n",
            "tensor(40.) tensor(6360.)\n",
            "tensor(28.) tensor(6372.)\n",
            "tensor(72.) tensor(16312.)\n",
            "tensor(56.) tensor(12488.)\n",
            "tensor(70.) tensor(16314.)\n",
            "tensor(92.) tensor(16292.)\n",
            "tensor(40.) tensor(9176.)\n",
            "tensor(46.) tensor(6354.)\n",
            "tensor(44.) tensor(6356.)\n",
            "tensor(44.) tensor(6356.)\n",
            "tensor(8.) tensor(6392.)\n",
            "tensor(12.) tensor(6388.)\n",
            "tensor(40.) tensor(6360.)\n",
            "tensor(42.) tensor(6358.)\n",
            "tensor(50.) tensor(9166.)\n",
            "tensor(70.) tensor(16314.)\n",
            "tensor(172.) tensor(112724.)\n",
            "tensor(70.) tensor(16314.)\n",
            "tensor(160.) tensor(92256.)\n",
            "tensor(238.) tensor(172818.)\n",
            "tensor(32.) tensor(6368.)\n",
            "tensor(50.) tensor(9166.)\n",
            "tensor(26.) tensor(6374.)\n",
            "tensor(44.) tensor(6356.)\n",
            "tensor(26.) tensor(6374.)\n",
            "tensor(68.) tensor(16316.)\n",
            "tensor(60.) tensor(12484.)\n",
            "tensor(68.) tensor(16316.)\n",
            "tensor(10.) tensor(6390.)\n",
            "tensor(42.) tensor(9174.)\n",
            "tensor(52.) tensor(12492.)\n",
            "tensor(140.) tensor(313460.)\n",
            "tensor(48.) tensor(6352.)\n",
            "tensor(28.) tensor(6372.)\n",
            "tensor(8.) tensor(6392.)\n",
            "tensor(98.) tensor(25502.)\n",
            "tensor(46.) tensor(6354.)\n",
            "tensor(72.) tensor(16312.)\n",
            "tensor(16.) tensor(6384.)\n",
            "tensor(68.) tensor(16316.)\n",
            "tensor(122.) tensor(82822.)\n",
            "tensor(24.) tensor(6376.)\n",
            "tensor(12.) tensor(6388.)\n",
            "tensor(172.) tensor(92244.)\n",
            "tensor(212.) tensor(159788.)\n",
            "tensor(40.) tensor(6360.)\n",
            "tensor(40.) tensor(6360.)\n",
            "tensor(38.) tensor(6362.)\n",
            "tensor(54.) tensor(6346.)\n",
            "tensor(10.) tensor(6390.)\n",
            "tensor(46.) tensor(9170.)\n",
            "tensor(70.) tensor(16314.)\n",
            "tensor(122.) tensor(82822.)\n",
            "tensor(34.) tensor(6366.)\n",
            "tensor(58.) tensor(12486.)\n",
            "tensor(134.) tensor(82810.)\n",
            "tensor(240.) tensor(172816.)\n",
            "tensor(36.) tensor(6364.)\n",
            "tensor(20.) tensor(6380.)\n",
            "tensor(12.) tensor(6388.)\n",
            "tensor(82.) tensor(16302.)\n",
            "tensor(12.) tensor(6388.)\n",
            "tensor(184.) tensor(135240.)\n",
            "tensor(58.) tensor(9158.)\n",
            "tensor(66.) tensor(16318.)\n",
            "tensor(42.) tensor(6358.)\n",
            "tensor(42.) tensor(6358.)\n",
            "tensor(10.) tensor(6390.)\n",
            "tensor(42.) tensor(6358.)\n",
            "tensor(44.) tensor(6356.)\n",
            "tensor(10.) tensor(6390.)\n",
            "tensor(72.) tensor(16312.)\n",
            "tensor(70.) tensor(16314.)\n",
            "tensor(90.) tensor(25510.)\n",
            "tensor(48.) tensor(6352.)\n",
            "tensor(18.) tensor(6382.)\n",
            "tensor(10.) tensor(6390.)\n",
            "tensor(30.) tensor(6370.)\n",
            "tensor(128.) tensor(102272.)\n",
            "tensor(56.) tensor(9160.)\n",
            "tensor(66.) tensor(12478.)\n",
            "tensor(42.) tensor(6358.)\n",
            "tensor(4.) tensor(6396.)\n",
            "tensor(18.) tensor(6382.)\n",
            "tensor(78.) tensor(16306.)\n",
            "tensor(16.) tensor(6384.)\n",
            "tensor(8.) tensor(6392.)\n",
            "tensor(24.) tensor(6376.)\n",
            "tensor(204.) tensor(135220.)\n",
            "tensor(196.) tensor(123708.)\n",
            "tensor(32.) tensor(6368.)\n",
            "tensor(8.) tensor(6392.)\n",
            "tensor(50.) tensor(9166.)\n",
            "tensor(46.) tensor(6354.)\n",
            "tensor(42.) tensor(6358.)\n",
            "tensor(204.) tensor(92212.)\n",
            "tensor(12.) tensor(6388.)\n",
            "tensor(22.) tensor(6378.)\n",
            "tensor(46.) tensor(6354.)\n",
            "tensor(70.) tensor(16314.)\n",
            "tensor(12.) tensor(6388.)\n",
            "tensor(30.) tensor(6370.)\n",
            "tensor(118.) tensor(57482.)\n",
            "tensor(12.) tensor(6388.)\n",
            "tensor(256.) tensor(159744.)\n",
            "tensor(124.) tensor(57476.)\n",
            "tensor(10.) tensor(6390.)\n",
            "tensor(36.) tensor(6364.)\n",
            "tensor(52.) tensor(9164.)\n",
            "tensor(42.) tensor(6358.)\n",
            "tensor(34.) tensor(6366.)\n",
            "tensor(72.) tensor(16312.)\n",
            "tensor(118.) tensor(135306.)\n",
            "tensor(72.) tensor(16312.)\n",
            "tensor(8.) tensor(6392.)\n",
            "tensor(202.) tensor(92214.)\n",
            "tensor(68.) tensor(16316.)\n",
            "tensor(34.) tensor(6366.)\n",
            "tensor(66.) tensor(12478.)\n",
            "tensor(96.) tensor(36768.)\n",
            "tensor(64.) tensor(16320.)\n",
            "tensor(50.) tensor(9166.)\n",
            "tensor(70.) tensor(16314.)\n",
            "tensor(28.) tensor(6372.)\n",
            "tensor(52.) tensor(9164.)\n",
            "tensor(32.) tensor(16352.)\n",
            "tensor(24.) tensor(6376.)\n",
            "tensor(34.) tensor(9182.)\n",
            "tensor(120.) tensor(172936.)\n",
            "tensor(60.) tensor(16324.)\n",
            "tensor(6.) tensor(6394.)\n",
            "tensor(120.) tensor(50056.)\n",
            "tensor(12.) tensor(6388.)\n",
            "tensor(2.) tensor(6398.)\n",
            "tensor(12.) tensor(6388.)\n",
            "tensor(42.) tensor(6358.)\n",
            "tensor(24.) tensor(6376.)\n",
            "tensor(50.) tensor(6350.)\n",
            "tensor(206.) tensor(123698.)\n",
            "tensor(42.) tensor(6358.)\n",
            "tensor(142.) tensor(65394.)\n",
            "tensor(62.) tensor(12482.)\n",
            "tensor(10.) tensor(6390.)\n",
            "tensor(76.) tensor(16308.)\n",
            "tensor(14.) tensor(6386.)\n",
            "tensor(42.) tensor(9174.)\n",
            "tensor(66.) tensor(16318.)\n",
            "tensor(36.) tensor(6364.)\n",
            "tensor(66.) tensor(9150.)\n",
            "tensor(204.) tensor(147252.)\n",
            "tensor(72.) tensor(16312.)\n",
            "tensor(10.) tensor(6390.)\n",
            "tensor(44.) tensor(9172.)\n",
            "tensor(10.) tensor(6390.)\n",
            "tensor(84.) tensor(20652.)\n",
            "tensor(154.) tensor(73830.)\n",
            "tensor(40.) tensor(6360.)\n",
            "tensor(64.) tensor(16320.)\n",
            "tensor(12.) tensor(6388.)\n",
            "tensor(14.) tensor(16370.)\n",
            "tensor(66.) tensor(16318.)\n",
            "Average testing F1 score with pure post-processing:  0.5116789\n",
            "Average testing precision with pure post-processing:  0.50586593\n",
            "Average testing recall with pure post-processing:  0.5483534\n",
            "Average testing specificity with pure post-processing:  0.99807304\n",
            "Average testing g-mean with pure post-processing:  0.69777787\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cd UFold/ && \\\n",
        "python ufold_test.py --test_files joined_test \\\n",
        "--model_pt ../PDB_unet_9.pt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K1qJOgles7VX",
        "outputId": "8c200ca4-b10e-4474-acf0-0bf76599db25"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading test file:  joined_test\n",
            "/content/UFold/ufold/data_generator.py:44: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  self.pairs = np.array([instance[-1] for instance in self.data])\n",
            "Max seq length  600\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "==========Start Loading==========\n",
            "==========Finish Loading==========\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:512: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3587.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:512: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3587.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:512: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3587.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:512: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3587.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:512: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3587.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:512: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3587.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            "Batch number:  0\n",
            "tensor(208.) tensor(147248.)\n",
            "tensor(162.) tensor(112734.)\n",
            "tensor(170.) tensor(92246.)\n",
            "tensor(72.) tensor(16312.)\n",
            "tensor(72.) tensor(16312.)\n",
            "tensor(62.) tensor(16322.)\n",
            "tensor(70.) tensor(16314.)\n",
            "tensor(46.) tensor(9170.)\n",
            "tensor(42.) tensor(6358.)\n",
            "tensor(42.) tensor(6358.)\n",
            "tensor(8.) tensor(6392.)\n",
            "tensor(38.) tensor(6362.)\n",
            "tensor(14.) tensor(6386.)\n",
            "tensor(36.) tensor(6364.)\n",
            "tensor(50.) tensor(6350.)\n",
            "tensor(38.) tensor(6362.)\n",
            "tensor(12.) tensor(6388.)\n",
            "tensor(72.) tensor(16312.)\n",
            "tensor(20.) tensor(6380.)\n",
            "tensor(38.) tensor(6362.)\n",
            "tensor(70.) tensor(16314.)\n",
            "tensor(10.) tensor(6390.)\n",
            "tensor(48.) tensor(9168.)\n",
            "tensor(146.) tensor(65390.)\n",
            "tensor(56.) tensor(6344.)\n",
            "tensor(66.) tensor(16318.)\n",
            "tensor(40.) tensor(6360.)\n",
            "tensor(28.) tensor(6372.)\n",
            "tensor(72.) tensor(16312.)\n",
            "tensor(56.) tensor(12488.)\n",
            "tensor(70.) tensor(16314.)\n",
            "tensor(92.) tensor(16292.)\n",
            "tensor(40.) tensor(9176.)\n",
            "tensor(46.) tensor(6354.)\n",
            "tensor(44.) tensor(6356.)\n",
            "tensor(44.) tensor(6356.)\n",
            "tensor(8.) tensor(6392.)\n",
            "tensor(12.) tensor(6388.)\n",
            "tensor(40.) tensor(6360.)\n",
            "tensor(42.) tensor(6358.)\n",
            "tensor(50.) tensor(9166.)\n",
            "tensor(70.) tensor(16314.)\n",
            "tensor(172.) tensor(112724.)\n",
            "tensor(70.) tensor(16314.)\n",
            "tensor(160.) tensor(92256.)\n",
            "tensor(238.) tensor(172818.)\n",
            "tensor(32.) tensor(6368.)\n",
            "tensor(50.) tensor(9166.)\n",
            "tensor(26.) tensor(6374.)\n",
            "tensor(44.) tensor(6356.)\n",
            "tensor(26.) tensor(6374.)\n",
            "tensor(68.) tensor(16316.)\n",
            "tensor(60.) tensor(12484.)\n",
            "tensor(68.) tensor(16316.)\n",
            "tensor(10.) tensor(6390.)\n",
            "tensor(42.) tensor(9174.)\n",
            "tensor(52.) tensor(12492.)\n",
            "tensor(140.) tensor(313460.)\n",
            "tensor(48.) tensor(6352.)\n",
            "tensor(28.) tensor(6372.)\n",
            "tensor(8.) tensor(6392.)\n",
            "tensor(98.) tensor(25502.)\n",
            "tensor(46.) tensor(6354.)\n",
            "tensor(72.) tensor(16312.)\n",
            "tensor(16.) tensor(6384.)\n",
            "tensor(68.) tensor(16316.)\n",
            "tensor(122.) tensor(82822.)\n",
            "tensor(24.) tensor(6376.)\n",
            "tensor(12.) tensor(6388.)\n",
            "tensor(172.) tensor(92244.)\n",
            "tensor(212.) tensor(159788.)\n",
            "tensor(40.) tensor(6360.)\n",
            "tensor(40.) tensor(6360.)\n",
            "tensor(38.) tensor(6362.)\n",
            "tensor(54.) tensor(6346.)\n",
            "tensor(10.) tensor(6390.)\n",
            "tensor(46.) tensor(9170.)\n",
            "tensor(70.) tensor(16314.)\n",
            "tensor(122.) tensor(82822.)\n",
            "tensor(34.) tensor(6366.)\n",
            "tensor(58.) tensor(12486.)\n",
            "tensor(134.) tensor(82810.)\n",
            "tensor(240.) tensor(172816.)\n",
            "tensor(36.) tensor(6364.)\n",
            "tensor(20.) tensor(6380.)\n",
            "tensor(12.) tensor(6388.)\n",
            "tensor(82.) tensor(16302.)\n",
            "tensor(12.) tensor(6388.)\n",
            "tensor(184.) tensor(135240.)\n",
            "tensor(58.) tensor(9158.)\n",
            "tensor(66.) tensor(16318.)\n",
            "tensor(42.) tensor(6358.)\n",
            "tensor(42.) tensor(6358.)\n",
            "tensor(10.) tensor(6390.)\n",
            "tensor(42.) tensor(6358.)\n",
            "tensor(44.) tensor(6356.)\n",
            "tensor(10.) tensor(6390.)\n",
            "tensor(72.) tensor(16312.)\n",
            "tensor(70.) tensor(16314.)\n",
            "tensor(90.) tensor(25510.)\n",
            "tensor(48.) tensor(6352.)\n",
            "tensor(18.) tensor(6382.)\n",
            "tensor(10.) tensor(6390.)\n",
            "tensor(30.) tensor(6370.)\n",
            "tensor(128.) tensor(102272.)\n",
            "tensor(56.) tensor(9160.)\n",
            "tensor(66.) tensor(12478.)\n",
            "tensor(42.) tensor(6358.)\n",
            "tensor(4.) tensor(6396.)\n",
            "tensor(18.) tensor(6382.)\n",
            "tensor(78.) tensor(16306.)\n",
            "tensor(16.) tensor(6384.)\n",
            "tensor(8.) tensor(6392.)\n",
            "tensor(24.) tensor(6376.)\n",
            "tensor(204.) tensor(135220.)\n",
            "tensor(196.) tensor(123708.)\n",
            "tensor(32.) tensor(6368.)\n",
            "tensor(8.) tensor(6392.)\n",
            "tensor(50.) tensor(9166.)\n",
            "tensor(46.) tensor(6354.)\n",
            "tensor(42.) tensor(6358.)\n",
            "tensor(204.) tensor(92212.)\n",
            "tensor(12.) tensor(6388.)\n",
            "tensor(22.) tensor(6378.)\n",
            "tensor(46.) tensor(6354.)\n",
            "tensor(70.) tensor(16314.)\n",
            "tensor(12.) tensor(6388.)\n",
            "tensor(30.) tensor(6370.)\n",
            "tensor(118.) tensor(57482.)\n",
            "tensor(12.) tensor(6388.)\n",
            "tensor(256.) tensor(159744.)\n",
            "tensor(124.) tensor(57476.)\n",
            "tensor(10.) tensor(6390.)\n",
            "tensor(36.) tensor(6364.)\n",
            "tensor(52.) tensor(9164.)\n",
            "tensor(42.) tensor(6358.)\n",
            "tensor(34.) tensor(6366.)\n",
            "tensor(72.) tensor(16312.)\n",
            "tensor(118.) tensor(135306.)\n",
            "tensor(72.) tensor(16312.)\n",
            "tensor(8.) tensor(6392.)\n",
            "tensor(202.) tensor(92214.)\n",
            "tensor(68.) tensor(16316.)\n",
            "tensor(34.) tensor(6366.)\n",
            "tensor(66.) tensor(12478.)\n",
            "tensor(96.) tensor(36768.)\n",
            "tensor(64.) tensor(16320.)\n",
            "tensor(50.) tensor(9166.)\n",
            "tensor(70.) tensor(16314.)\n",
            "tensor(28.) tensor(6372.)\n",
            "tensor(52.) tensor(9164.)\n",
            "tensor(32.) tensor(16352.)\n",
            "tensor(24.) tensor(6376.)\n",
            "tensor(34.) tensor(9182.)\n",
            "tensor(120.) tensor(172936.)\n",
            "tensor(60.) tensor(16324.)\n",
            "tensor(6.) tensor(6394.)\n",
            "tensor(120.) tensor(50056.)\n",
            "tensor(12.) tensor(6388.)\n",
            "tensor(2.) tensor(6398.)\n",
            "tensor(12.) tensor(6388.)\n",
            "tensor(42.) tensor(6358.)\n",
            "tensor(24.) tensor(6376.)\n",
            "tensor(50.) tensor(6350.)\n",
            "tensor(206.) tensor(123698.)\n",
            "tensor(42.) tensor(6358.)\n",
            "tensor(142.) tensor(65394.)\n",
            "tensor(62.) tensor(12482.)\n",
            "tensor(10.) tensor(6390.)\n",
            "tensor(76.) tensor(16308.)\n",
            "tensor(14.) tensor(6386.)\n",
            "tensor(42.) tensor(9174.)\n",
            "tensor(66.) tensor(16318.)\n",
            "tensor(36.) tensor(6364.)\n",
            "tensor(66.) tensor(9150.)\n",
            "tensor(204.) tensor(147252.)\n",
            "tensor(72.) tensor(16312.)\n",
            "tensor(10.) tensor(6390.)\n",
            "tensor(44.) tensor(9172.)\n",
            "tensor(10.) tensor(6390.)\n",
            "tensor(84.) tensor(20652.)\n",
            "tensor(154.) tensor(73830.)\n",
            "tensor(40.) tensor(6360.)\n",
            "tensor(64.) tensor(16320.)\n",
            "tensor(12.) tensor(6388.)\n",
            "tensor(14.) tensor(16370.)\n",
            "tensor(66.) tensor(16318.)\n",
            "Average testing F1 score with pure post-processing:  0.59166515\n",
            "Average testing precision with pure post-processing:  0.57493496\n",
            "Average testing recall with pure post-processing:  0.62931424\n",
            "Average testing specificity with pure post-processing:  0.99842584\n",
            "Average testing g-mean with pure post-processing:  0.7544084\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}